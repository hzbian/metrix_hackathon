{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1838cd8-7732-42b7-a4de-bdac716e8d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import pickle\n",
    "import errno\n",
    "from ray_nn.data.lightning_data_module import DefaultDataModule\n",
    "from ray_nn.nn.xy_hist_data_models import Model, MetrixXYHistSurrogate, StandardizeXYHist\n",
    "#from ray_nn.nn.xy_hist_data_models_old import MetrixXYHistSurrogateOld\n",
    "import glob\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from ray_nn.nn.xy_hist_data_models import StandardizeXYHist\n",
    "from ray_tools.simulation.torch_datasets import (\n",
    "    BalancedMemoryDataset,\n",
    "    HistDataset,\n",
    ")\n",
    "from scipy.stats import ttest_rel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f65ab3-a993-4969-9802-0521e735eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate random data\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = np.random.rand(100)\n",
    "\n",
    "# Create the plot with specific size\n",
    "plt.figure(figsize=(4.3, 1.7))\n",
    "plt.plot(x, y, color='teal', linewidth=2)\n",
    "plt.title(\"Random Plot\", fontsize=10)\n",
    "plt.xlabel(\"X-axis\", fontsize=8)\n",
    "plt.ylabel(\"Y-axis\", fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3c4f04-10b3-42ae-b93d-1fb9306ddde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_checkpoint_path(identifier, prefix=\"outputs/xy_hist\", suffix=\"checkpoints\"):\n",
    "    \"\"\"\n",
    "    Get the checkpoint file path with the highest step for a given identifier.\n",
    "    \n",
    "    Args:\n",
    "        identifier (str): The identifier for the checkpoint folder.\n",
    "        prefix (str): The base directory where checkpoints are stored.\n",
    "        suffix (str): The subdirectory containing checkpoint files.\n",
    "        \n",
    "    Returns:\n",
    "        str: Full path to the checkpoint file with the highest step, or None if no files found.\n",
    "    \"\"\"\n",
    "    base_path = os.path.join(prefix, identifier, suffix)\n",
    "    if not os.path.exists(base_path) or not os.path.isdir(base_path):\n",
    "        raise FileNotFoundError(\n",
    "            errno.ENOENT, os.strerror(errno.ENOENT), base_path)\n",
    "    \n",
    "    highest_step = -1\n",
    "    highest_ckpt = None\n",
    "    step_pattern = re.compiler(\"step=(\\d+)\\.ckpt$\")\n",
    "    \n",
    "    for file_name in os.listdir(base_path):\n",
    "        match = step_pattern.search(file_name)\n",
    "        if match:\n",
    "            step = int(match.group(1))\n",
    "            if step > highest_step:\n",
    "                highest_step = step\n",
    "                highest_ckpt = file_name\n",
    "    \n",
    "    if highest_ckpt:\n",
    "        return os.path.join(base_path, highest_ckpt)\n",
    "    return None\n",
    "\n",
    "@staticmethod\n",
    "def result_dict_to_latex(statistics_dict, reference_key=\"ref\"):\n",
    "    if len(result_dict) < 4:\n",
    "        alignment = \"l\" * len(statistics_dict)\n",
    "        table_environment = \"tabular\"\n",
    "    else:\n",
    "        alignment = r\"\"\"*{\"\"\"+str(len(statistics_dict))+r\"\"\"}{>{\\centering\\arraybackslash}X}\"\"\"\n",
    "        table_environment = \"tabularx\"\n",
    "    \n",
    "    if table_environment ==\"tabularx\":\n",
    "        text_width =  r\"\"\"{\\textwidth}\"\"\"\n",
    "    else:\n",
    "        text_width = \"\"\n",
    "\n",
    "    output_string = (\n",
    "        r\"\"\"\n",
    "    \\begin{\"\"\"+table_environment+r\"\"\"}\"\"\"+text_width+r\"\"\"{p{2.5cm}|\"\"\"+\n",
    "    alignment    \n",
    "        + r\"\"\"}\n",
    "    \\hline\"\"\"\n",
    "        + \"\\n\"\n",
    "    )\n",
    "    scenarios = [k+r\" $\\pm\\sigma$ (\\acs{CI})\" for k in statistics_dict.keys()]\n",
    "    keys = [\"Metric\"] + scenarios\n",
    "    output_string += \" & \".join(keys) + r\" \\\\\" + \"\\n\" \n",
    "    output_string += r\"\\hline\" + \"\\n\"\n",
    "    \n",
    "    model_keys = list(list(statistics_dict.values())[0].keys())\n",
    "\n",
    "    for model_key in model_keys:\n",
    "        model_row = [model_key]\n",
    "        for (mean, std_dev, is_best, is_significant, p_value) in [v[model_key] for v in statistics_dict.values()]:\n",
    "            model_row_element = f\"{mean:.2e}\".replace(\"e+0\", \"e+\").replace(\"e-0\", \"e-\")\n",
    "            if is_best:\n",
    "                model_row_element = r\"\\textbf{\" + model_row_element + r\"}\"\n",
    "            model_row_element = model_row_element+r\" $\\pm$ \"+f\"{std_dev:.2e}\".replace(\"e+0\", \"e+\").replace(\"e-0\", \"e-\")\n",
    "            if not model_key == reference_key:\n",
    "                model_row_element += f\" ({p_value[0]:.2e}, {p_value[1]:.2e})\".replace(\"e+0\", \"e+\").replace(\"e-0\", \"e-\")\n",
    "                if is_significant:\n",
    "                    model_row_element += r\"$\\dagger$\"\n",
    "            model_row += [model_row_element]\n",
    "        output_string += \" & \".join(model_row) + r\" \\\\\" + \"\\n\"\n",
    "\n",
    "    output_string += r\"\"\"\\hline\n",
    "    \\end{\"\"\"+table_environment+r\"\"\"}\"\"\"\n",
    "    return output_string\n",
    "def evaluate_model_dict_to_result_dict(model_dict):\n",
    "    result_dict = {}\n",
    "    for scenario_name, scenario_subset in tqdm(metrics_dict.items()):\n",
    "        result_dict[scenario_name] = {model_key: evaluate(model, scenario_subset) for model_key, model in model_dict.items()}\n",
    "    return result_dict\n",
    "\n",
    "@staticmethod\n",
    "def significant_confidence_levels(group_A, group_B, confidence=0.99):\n",
    "    ci = ttest_rel(group_A.flatten().cpu(), group_B.flatten().cpu()).confidence_interval(confidence_level=confidence)\n",
    "    confidence_interval = (ci.low.item(), ci.high.item())\n",
    "    return not (confidence_interval[0] < 0. and confidence_interval[1] > 0.), confidence_interval\n",
    "\n",
    "\n",
    "def statistics(result_dict, reference_key=\"ref\"):\n",
    "    min_mean = float('inf')\n",
    "    statistics_dict = {}\n",
    "    for key, value in result_dict.items():\n",
    "        mean = value.mean()\n",
    "        statistics_dict[key] = (mean.item(), value.std().item())\n",
    "        if mean < min_mean:\n",
    "            min_mean_key = key\n",
    "            min_mean = mean\n",
    "\n",
    "    for key, value in result_dict.items():\n",
    "         statistics_dict[key] =  statistics_dict[key] + (key==min_mean_key,) + significant_confidence_levels(value, result_dict[reference_key])\n",
    "         diff = (result_dict[key] - result_dict[min_mean_key]).flatten().abs().cpu()\n",
    "         mean = torch.mean(diff)\n",
    "         std_dev = torch.std(diff)\n",
    "    return statistics_dict\n",
    "\n",
    "def model_paths_to_model_dict(model_paths):\n",
    "    models_dict = {}\n",
    "    for key, identifier in model_paths.items():\n",
    "        path = get_checkpoint_path(identifier)\n",
    "        models_dict[key] = MetrixXYHistSurrogate.load_from_checkpoint(\n",
    "        checkpoint_path=path,\n",
    "        #hparams_file=\"/path/to/experiment/version/hparams.yaml\",\n",
    "        map_location=None,\n",
    "        )\n",
    "    return models_dict\n",
    "def evaluate(model, subset='good', load_len=2000000):\n",
    "    model.criterion = torch.nn.MSELoss(reduction='none')\n",
    "    standardizer = model.standardizer\n",
    "    output_list = []\n",
    "    sub_groups = ['parameters', 'histogram/ImagePlane', 'n_rays/ImagePlane']\n",
    "    transforms=[lambda x: x[:, 1:].float(), lambda x: standardizer(x.flatten(start_dim=1).float()), lambda x: x.int()]\n",
    "    dataset = HistDataset([13, 14], \"datasets/metrix_simulation/ray_emergency_surrogate_50+50+z+-30\", \"histogram_*.h5\", sub_groups, transforms, normalize_sub_groups=['parameters'], load_max=load_len//2)\n",
    "    memory_dataset = BalancedMemoryDataset(dataset=dataset, min_n_rays=1, subset=subset)\n",
    "    del dataset\n",
    "    num_workers = 0\n",
    "    datamodule = DefaultDataModule(test_dataset=memory_dataset, num_workers=num_workers, batch_size_val=1024)\n",
    "\n",
    "    for x, y in tqdm(datamodule.test_dataloader(), leave=False):\n",
    "        with torch.no_grad():\n",
    "            #y_hat = model(x.to(model.device))\n",
    "            x = x.to(model.device)\n",
    "            y = y.to(model.device)\n",
    "            output_list.append(model.test_step((x,y)).mean(dim=-1))\n",
    "    if len(output_list) > 0:\n",
    "        output_tensor = torch.cat(output_list)\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2363cbe3-c3af-4d38-a54c-65c936c840b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {r\"Nonempty \\acs{MSE}\":\"good\", r\"Empty \\acs{MSE}\":\"bad\"}\n",
    "model_paths = {\n",
    "    \"ref\": \"s021yw7n\",\n",
    "    #\"gbp_2\": \"cuvbjeb9\",\n",
    "    #\"gbp_4\": \"dbv0tc5h\",\n",
    "    #\"plat_10\": \"2qbmgk8z\",\n",
    "    #\"5_l\": \"d42xqlbe\",\n",
    "    #\"6_l\": \"zpd30wi1\",\n",
    "    #\"blow_1\": \"mwko1ldx\",\n",
    "    #\"blow_3\": \"y8gw1ebu\",\n",
    "    #\"min_n_1\": \"x6pch3kp\",\n",
    "    #\"min_n_20\": \"yjqv9nlo\",\n",
    "    \"adam_w\": \"sias70j8\",\n",
    "    #\"ReLU\": \"tqyfx4y5\",\n",
    "              }\n",
    "model_dict = model_paths_to_model_dict(model_paths)\n",
    "\n",
    "result_dict = evaluate_model_dict_to_result_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b63b2a-0dda-4f98-849c-7fa7d6eb452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_dict = {key: statistics(value) for key, value in result_dict.items()}\n",
    "print(result_dict_to_latex(statistics_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ee107f-bf4d-4fe8-871e-682ba45c21c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataloader(path, dataset_ids = [10, 11], load_len=None, batch_size=128, num_workers=0, standardizer=StandardizeXYHist(), sub_groups=['parameters', 'histogram/ImagePlane', 'n_rays/ImagePlane'], normalize_sub_groups = ['parameters'], file_pattern = 'histogram_*.h5', subset=None):\n",
    "    transforms = [lambda x: x[:, 1:].float(), lambda x: standardizer(x.flatten(start_dim=1).float()), lambda x: x.int()]\n",
    "    hist_dataset = HistDataset(dataset_ids, path, file_pattern, sub_groups, transforms, normalize_sub_groups, load_max=load_len)\n",
    "    if subset is not None:\n",
    "        hist_dataset = BalancedMemoryDataset(hist_dataset, subset=subset)\n",
    "    datamodule = DefaultDataModule(train_dataset=None, val_dataset=None, test_dataset=hist_dataset, batch_size_train=batch_size, batch_size_val=batch_size, num_workers=num_workers)\n",
    "    return datamodule.test_dataloader()\n",
    "\n",
    "def calculate_mses(model, dataloader):\n",
    "    mses = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(dataloader):\n",
    "            cpu_model = model.model_orig.cpu()\n",
    "            mses.append(((cpu_model(i[0])-i[1])**2).mean(dim=-1))\n",
    "    mses_tensor = torch.hstack(mses)\n",
    "    return mses_tensor\n",
    "\n",
    "def mse_statistics(path, mses_tensor):\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(4.7, 3.0))\n",
    "    print((mses_tensor < 1e-5).sum(), mses_tensor.max())\n",
    "    reduced = mses_tensor[(mses_tensor > 1e-5)]\n",
    "    plt.hist(mses_tensor.cpu(), bins=100)\n",
    "    plt.axvline(x=1e-5, color='red', linestyle='--', linewidth=1, label=r'$x=1 \\times 10^{-5}$')\n",
    "    plt.ylabel(\"Count [#]\")\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(\"MSE\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path,\"mse_hist.pdf\"), bbox_inches=\"tight\")\n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b32d48-509d-4a7c-9549-33d8fd888ee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root_dir = ''\n",
    "\n",
    "model_path = os.path.join(root_dir, \"outputs/xy_hist/s021yw7n/checkpoints/epoch=235-step=70000000.ckpt\")\n",
    "model = Model(path=model_path)\n",
    "\n",
    "path = os.path.join(root_dir,'datasets/metrix_simulation/ray_emergency_surrogate_50+50+z+-30/')\n",
    "dataloader = test_dataloader(path)\n",
    "mses_tensor = calculate_mses(model, dataloader=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8341a491-573d-4927-8096-e9079ea1c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_statistics(os.path.join(root_dir,\"outputs/\"), mses_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ec9a1f-2d1d-4a87-a7fb-99f9d3e342f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f26bc9-e2fc-4570-a863-03c398fd8a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = test_dataloader(path, subset='good')\n",
    "for x in dataloader:\n",
    "    prediction = model.model_orig(x[0].to(model.device))\n",
    "    ground_truth = x[1]\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de92308-72b6-45a7-9ead-f8293eb2c75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = MetrixXYHistSurrogate.plot_data_3(prediction[:3].detach().cpu().numpy(), ground_truth[:3].detach().cpu().numpy())\n",
    "fig.savefig(os.path.join(root_dir, \"outputs/surrogate_vs_ray_ui.pdf\"))\n",
    "\n",
    "with open(os.path.join(root_dir, \"outputs/prediction.pkl\"), 'wb') as handle:\n",
    "    pickle.dump(prediction, handle)\n",
    "with open(os.path.join(root_dir, \"outputs/ground_truth.pkl\"), 'wb') as handle:\n",
    "    pickle.dump(ground_truth, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4680d-5cb3-49dd-a7e0-9704ea391408",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(root_dir, \"outputs/prediction.pkl\"), 'rb') as f:\n",
    "    prediction = pickle.load(f)\n",
    "with open(os.path.join(root_dir, \"outputs/ground_truth.pkl\"), 'rb') as f:\n",
    "    ground_truth = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec2e4c-ad37-435b-a5f6-10f706ceb115",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = MetrixXYHistSurrogate.plot_data_3(prediction[:3].detach().cpu().numpy(), ground_truth[:3].detach().cpu().numpy())\n",
    "fig.savefig(os.path.join(root_dir, \"outputs/surrogate_vs_ray_ui.pdf\"),  bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f96b989-21ce-4008-ad42-0471e7fff70c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
