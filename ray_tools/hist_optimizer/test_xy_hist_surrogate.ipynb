{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab8113-e0e8-44e6-a38c-a7889f640d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import glob\n",
    "import tqdm\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../..\")\n",
    "from hist_optimizer import tensor_to_param_container, mse_engines_comparison, Model, find_good_offset_problem, optimize_smart_walker, optimize_brute, evaluate_evaluation_method, plot_param_tensors, tensor_list_to_param_container_list, param_tensor_to_ray_outputs, compare_with_reference\n",
    "\n",
    "from ray_tools.base.transform import MultiLayer\n",
    "from ray_nn.data.lightning_data_module import DefaultDataModule\n",
    "from ray_nn.nn.xy_hist_data_models import MetrixXYHistSurrogate, StandardizeXYHist, HistSurrogateEngine\n",
    "from ray_tools.base.engine import RayEngine\n",
    "from ray_tools.base.backend import RayBackendDockerRAYUI\n",
    "from ray_tools.simulation.torch_datasets import BalancedMemoryDataset, MemoryDataset, RayDataset\n",
    "from datasets.metrix_simulation.config_ray_emergency_surrogate import PARAM_CONTAINER_FUNC as params\n",
    "from ray_optim.plot import Plot\n",
    "import matplotlib.pyplot as plt\n",
    "from ray_nn.data.transform import Select\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe67c8a6-0a58-49d5-8c68-a6c129ca6eb2",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b643820-f6e9-49cb-97e2-6a96f940fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = RayEngine(rml_basefile='../../rml_src/METRIX_U41_G1_H1_318eV_PS_MLearn_1.15.rml',\n",
    "                                exported_planes=[\"ImagePlane\"],\n",
    "                                ray_backend=RayBackendDockerRAYUI(docker_image='ray-ui-service',\n",
    "                                                                  docker_container_name='ray-ui-service-test',\n",
    "                                                                  dockerfile_path='../../ray_docker/rayui',\n",
    "                                                                  ray_workdir='/dev/shm/ray-workdir',\n",
    "                                                                  verbose=False),\n",
    "                                num_workers=-1,\n",
    "                                as_generator=False)\n",
    "surrogate_engine = HistSurrogateEngine(checkpoint_path=\"../../outputs/xy_hist/qhmpdasi/checkpoints/epoch=295-step=118652488.ckpt\")\n",
    "\n",
    "model = Model(path=\"../../outputs/xy_hist/qhmpdasi/checkpoints/epoch=295-step=118652488.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7763be-2106-4558-8b5c-33224786fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot.plot_engines_comparison(engine, surrogate_engine, [tensor_to_param_container(torch.ones((34))*0.5)], MultiLayer([0.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4318fe85-2d93-4312-ac5a-b089c8f9c707",
   "metadata": {},
   "source": [
    "# Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf51d90-a077-4aea-98dd-d88b38fc077f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_len: int | None = None #10000\n",
    "h5_files = list(glob.iglob('../../datasets/metrix_simulation/ray_emergency_surrogate/data_raw_*.h5'))\n",
    "dataset = RayDataset(h5_files=h5_files,\n",
    "                        sub_groups=['1e5/params',\n",
    "                                    '1e5/ray_output/ImagePlane/histogram', '1e5/ray_output/ImagePlane/n_rays'], transform=Select(keys=['1e5/params', '1e5/ray_output/ImagePlane/histogram', '1e5/ray_output/ImagePlane/n_rays'], search_space=params(), non_dict_transform={'1e5/ray_output/ImagePlane/histogram': surrogate_engine.model.standardizer}))\n",
    "\n",
    "\n",
    "bal_memory_dataset = BalancedMemoryDataset(dataset=dataset, load_len=load_len, min_n_rays=1)\n",
    "memory_dataset = MemoryDataset(dataset=dataset, load_len=load_len)\n",
    "datamodule = DefaultDataModule(dataset=bal_memory_dataset, num_workers=4)\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup(stage=\"test\")\n",
    "test_dl = datamodule.test_dataloader()\n",
    "\n",
    "unbal_datamodule = DefaultDataModule(dataset=memory_dataset, num_workers=4)\n",
    "unbal_datamodule.prepare_data()\n",
    "unbal_datamodule.setup(stage=\"test\")\n",
    "unbal_test_dl = unbal_datamodule.test_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98253db-b210-4ab2-983f-40c050995119",
   "metadata": {},
   "source": [
    "## Maximum distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b4e764-e7da-4764-9e8c-a66a8472e46f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "value_list = []\n",
    "params_list = []\n",
    "\n",
    "for i in tqdm.tqdm(unbal_test_dl):\n",
    "    biggest = i[1].flatten(start_dim=1)\n",
    "    biggest, _ = i[1].flatten(start_dim=1).max(dim=1)\n",
    "    mask = biggest > 0.8\n",
    "    value_list.append(biggest[mask])\n",
    "    params_list.append(i[0][mask])\n",
    "value_tensor = torch.cat(value_list)\n",
    "params_tensor = torch.cat(params_list)\n",
    "\n",
    "torch.save(value_tensor, 'outputs/values.pt')\n",
    "torch.save(params_tensor, 'outputs/params.pt')\n",
    "plt.hist(value_tensor)\n",
    "plt.savefig('outputs/max_dist_hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de822f-7b2f-4b1b-8ce3-5075f5de708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_tensor = torch.load('outputs/values.pt')\n",
    "params_tensor = torch.load('outputs/params.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdc65fd-e313-4628-9287-388b7e95c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "for i in tqdm.tqdm(test_dl):\n",
    "    #print(len(i[0][:10]))\n",
    "    t = tensor_list_to_param_container_list(i[0][:10])\n",
    "    print(len(t))\n",
    "    out = [engine.run(t, XYHistogram(50, (-10., 10.), (-3., 3.))) for i in tqdm.trange(2)]\n",
    "    break\n",
    "#['ray_output']['ImagePlane']['histogram']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b620b358-ba48-49a2-ad0f-89e4a3dca9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out[0][0]['ray_output']['ImagePlane']['histogram'])\n",
    "len(out), len(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cb59fd-09a9-4d71-9f60-a35e971980d5",
   "metadata": {},
   "source": [
    "# Special sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a67b85-035a-4433-b00f-80af733a4479",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/special_sample_168_selected.pkl\", \"rb\") as f:\n",
    "    special_sample = pickle.load(f, fix_imports=True, encoding='ASCII', errors='strict', buffers=None)\n",
    "observed_params = special_sample.uncompensated_parameters\n",
    "\n",
    "for param_container in observed_params:\n",
    "    for label in ['ImagePlane.translationXerror', 'ImagePlane.translationYerror', 'ImagePlane.translationZerror']:\n",
    "        if label in list(param_container.keys()):\n",
    "            del param_container[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f574994c-891f-4241-8ebc-69923812263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(observed_params)\n",
    "Plot.plot_engines_comparison(engine, surrogate_engine, observed_params[:5], MultiLayer([0.]), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aedafb7-548b-47ee-bdb1-a33c346eda44",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncompensated_parameters = [elem.clone() for elem in special_sample.uncompensated_parameters]\n",
    "for elem in uncompensated_parameters:\n",
    "    elem.perturb(special_sample.target_params)\n",
    "uncompensated_parameters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903329a4-b9af-4627-a406-8d93a8b058f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot.plot_engines_comparison(engine, surrogate_engine, uncompensated_parameters, MultiLayer([0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f251daa-c4f3-4461-af8d-37f6522f99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_comparison, x_simulation_hist, y_simulation_hist = mse_engines_comparison(engine, surrogate_engine, uncompensated_parameters[:5], MultiLayer([0.]))\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "for hist in x_simulation_hist:\n",
    "    ax[0].plot(hist, alpha=0.3)\n",
    "for hist in y_simulation_hist:\n",
    "    ax[1].plot(hist, alpha=0.3)\n",
    "ax[2].hist(mse_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a5863a-6470-42a4-9f13-3f7b5abe0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_loc_list = []\n",
    "good_param_list = []\n",
    "batch_size = 5000\n",
    "for i in tqdm.trange(15000//batch_size):\n",
    "    param_container = [tensor_to_param_container(torch.rand((34,))) for _ in range(batch_size)]\n",
    "    surrogate_out = surrogate_engine.run(param_container, MultiLayer([0.]))\n",
    "    for j in range(len(param_container)):\n",
    "        output = surrogate_out[j]['ray_output']['ImagePlane']['xy_hist']\n",
    "        if output.x_loc.sum() > 0.5:\n",
    "            x_loc_list.append(output.x_loc.sum())\n",
    "            good_param_list.append(param_container[j])\n",
    "\n",
    "observed_containers_tensor = torch.vstack([surrogate_engine.select({\"1e5/params\":param_container})[0] for param_container in observed_params])\n",
    "good_containers_tensor = torch.vstack([surrogate_engine.select({\"1e5/params\":param_container})[0] for param_container in good_param_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a886aeb-f0b4-4971-84e8-4b2b3662ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "for i in range(good_containers_tensor.shape[0]):\n",
    "    plt.plot(good_containers_tensor[i], c = 'blue', alpha=0.1)\n",
    "for i in range(observed_containers_tensor.shape[0]):\n",
    "    plt.plot(observed_containers_tensor[i], alpha=0.8)\n",
    "plt.legend([\"special\", \"good\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418cb63a-b773-4aab-854b-dec4755ccc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = value_tensor > 0.44\n",
    "out = ((params_tensor - observed_containers_tensor[0].unsqueeze(0))**2)/2.\n",
    "out = out.mean(dim=1)\n",
    "out_sorted, indices = torch.sort(out)\n",
    "#part_indices = indices[:5]\n",
    "#print(part_indices.shape)\n",
    "#min_arg = out.argmin()\n",
    "#plt.hist(out.mean(dim=1))\n",
    "#plt.plot(params_tensor[min_arg])\n",
    "#plt.plot(observed_containers_tensor[0])\n",
    "for i in indices[:1]:\n",
    "    plt.plot(params_tensor[i])\n",
    "Plot.plot_engines_comparison(engine, surrogate_engine, [tensor_to_param_container(params_tensor[min_arg]) for min_arg in indices[:1]], MultiLayer([0.]), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43f2ae6-d74d-40db-b064-a727184380eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#surrogate_engine.run(observed_params)\n",
    "model = MetrixXYHistSurrogate.load_from_checkpoint(\"outputs/xy_hist/i7sryekx_copy/checkpoints/epoch=186-step=45716638.ckpt\")\n",
    "select = Select(keys=['1e5/params'], omit_ray_params=['U41_318eV.numberRays'], search_space=params(), non_dict_transform={'1e5/ray_output/ImagePlane/histogram': model.standardizer})\n",
    "param_containers_tensor = torch.vstack([select({\"1e5/params\":param_container})[0] for param_container in observed_params])\n",
    "with torch.no_grad():\n",
    "    out_model = model(param_containers_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e4311-ab69-4692-a340-5f0cb3342039",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = {\"ImagePlane\": transform for transform in cfg_transforms}\n",
    "out_engine = engine.run(observed_params, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636cd240-dc8b-48bf-937c-7c39caa881fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_simulations = surrogate_engine.model.standardizer(torch.vstack([element['ray_output']['ImagePlane']['histogram'].flatten(start_dim=0) for element in out_engine]))\n",
    "a = ((standardized_simulations - out_model)**2).mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7500019-8d32-4055-b085-3311b7bdeb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933e278-11bf-4216-bdb2-e6643ed5d668",
   "metadata": {},
   "source": [
    "# Good params vs. bad params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7513437-7f9c-44b0-8793-e9549a488ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = []\n",
    "num_rays_list = []\n",
    "for i in tqdm.tqdm(memory_dataset):\n",
    "    params_list.append(i[0])\n",
    "    num_rays_list.append(i[2])\n",
    "params_tensor = torch.vstack(params_list)\n",
    "num_rays_tensor= torch.vstack(num_rays_list)\n",
    "plt.hist(torch.tensor(num_rays_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f571f-4de1-43c0-b71e-df26e91d5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest = torch.tensor(num_rays_list).argmax()\n",
    "test_parameters = memory_dataset[biggest][0]\n",
    "param_container_list = [tensor_to_param_container(test_parameters)]\n",
    "\n",
    "fig, ax = plt.subplots(1,2, sharey=True, squeeze=False)\n",
    "\n",
    "x_simulation_hist_list = []\n",
    "y_simulation_hist_list = []\n",
    "for i in tqdm.trange(20):\n",
    "    out = engine.run(param_container_list, MultiLayer([0.]))\n",
    "    out_simulation = out[-1]['ray_output']['ImagePlane']['0.0']\n",
    "    x_simulation_hist, _ = torch.histogram(out_simulation.x_loc,bins=50, range=[-10, 10])\n",
    "    y_simulation_hist, _ = torch.histogram(out_simulation.y_loc,bins=50, range=[-3, 3])\n",
    "    x_simulation_hist_list.append(x_simulation_hist / 22594.)\n",
    "    y_simulation_hist_list.append(y_simulation_hist / 22594.)\n",
    "    \n",
    "    ax[0, 0].plot(torch.linspace(-10, 10, 50), x_simulation_hist / 22594.)\n",
    "    ax[0, 1].plot(torch.linspace(-3, 3, 50), y_simulation_hist / 22594.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aed3db-467f-48ef-8886-f39faab1cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_simulation_hist_tens = torch.vstack(x_simulation_hist_list)\n",
    "y_simulation_hist_tens = torch.vstack(y_simulation_hist_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043fc52-8c01-487f-a2f8-cef90a8be1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_simulation_hist_tens.var(dim=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc62cae5-f272-41db-b531-ca271b79475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_simulation_hist_tens.mean(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8463884f-efac-4924-acb9-bcf050cc3494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "mask = num_rays_tensor > 100.\n",
    "data_tensor = params_tensor[mask.flatten()]\n",
    "data_tensor = data_tensor[:,:4]\n",
    "class_tensor = num_rays_tensor[mask]\n",
    "\n",
    "data_np = data_tensor.numpy()\n",
    "class_np = class_tensor.numpy().flatten()\n",
    "\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2)\n",
    "umap_embedding = umap_model.fit_transform(data_np)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(umap_embedding[:, 0], umap_embedding[:, 1], c=class_np, cmap='Spectral', s=5)\n",
    "plt.colorbar(scatter)\n",
    "plt.title('UMAP projection of the dataset')\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0bf724-e188-4443-b1c9-bcc265cb445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne_model = TSNE(n_components=2, perplexity=30, learning_rate=200, max_iter=1000)\n",
    "tsne_embedding = tsne_model.fit_transform(data_np)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(tsne_embedding[:, 0], tsne_embedding[:, 1], c=class_np, cmap='Spectral', s=5)\n",
    "plt.colorbar(scatter)\n",
    "plt.title('t-SNE projection of the dataset')\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a61f44c-0ba3-4eec-97c2-31fdeac4cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from ray_nn.nn.xy_hist_data_models import MetrixXYHistSurrogate, StandardizeXYHist\n",
    "from ray_tools.simulation.torch_datasets import MemoryDataset, RayDataset\n",
    "from datasets.metrix_simulation.config_ray_emergency_surrogate import PARAM_CONTAINER_FUNC as params\n",
    "from torch.utils.data import DataLoader\n",
    "from ray_nn.data.transform import Select\n",
    "\n",
    "\n",
    "model = MetrixXYHistSurrogate.load_from_checkpoint(\"outputs/xy_hist/qhmpdasi/checkpoints/epoch=295-step=118652488.ckpt\")\n",
    "model.to(torch.device('cpu'))\n",
    "model.compile()\n",
    "model.eval()\n",
    "\n",
    "load_len: int | None = None\n",
    "h5_files = list(glob.iglob('datasets/metrix_simulation/ray_emergency_surrogate/selected/data_raw_*.h5'))\n",
    "dataset = RayDataset(h5_files=h5_files,\n",
    "                        sub_groups=['1e5/params',\n",
    "                                    '1e5/ray_output/ImagePlane/histogram', '1e5/ray_output/ImagePlane/n_rays'], transform=Select(keys=['1e5/params', '1e5/ray_output/ImagePlane/histogram', '1e5/ray_output/ImagePlane/n_rays'], search_space=params(), non_dict_transform={'1e5/ray_output/ImagePlane/histogram': model.standardizer}))\n",
    "\n",
    "\n",
    "memory_dataset = MemoryDataset(dataset=dataset, load_len=load_len)\n",
    "\n",
    "train_dataloader = DataLoader(memory_dataset, batch_size=2048, shuffle=False, num_workers=0)\n",
    "\n",
    "errors_list = []\n",
    "with torch.no_grad():\n",
    "    for par_input, label, _ in tqdm.tqdm(train_dataloader):\n",
    "        out = model(par_input)\n",
    "        label = label.flatten(start_dim=1)\n",
    "        b = ((label - out)**2).mean(dim=1)\n",
    "        errors_list.append(b)\n",
    "errors_tensor = torch.cat(errors_list)\n",
    "\n",
    "plt.hist(errors_tensor)\n",
    "plt.savefig('outputs/dataset_errors_hist.png')\n",
    "torch.save(errors_tensor, 'outputs/dataset_errors.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19d0003-49c6-4b29-8ae4-3a0e3eadc779",
   "metadata": {},
   "source": [
    "# Look with model for new sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764b435d-3734-46db-bbae-f6d3710e1938",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_offset = 0.2\n",
    "offsets_selected, uncompensated_parameters_selected, compensated_parameters_selected = find_good_offset_problem(model, max_offset=max_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4619825c-6b7b-40f5-897b-abca776a6466",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    observed_rays = model(compensated_parameters_selected)\n",
    "    \n",
    "loss_min_params, loss, loss_min_list = optimize_smart_walker(model, observed_rays, uncompensated_parameters_selected, iterations=10, num_candidates=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f3671d-08ec-44a9-98c4-d2996f0b389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_min_params, loss, loss_min_list = optimize_brute(model, observed_rays, uncompensated_parameters_selected, iterations=10, num_candidates=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f650064-9e24-4a1b-ac4a-7a60d4d0dcc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    observed_rays = model(compensated_parameters_selected)\n",
    "    \n",
    "loss_min_params, loss, loss_min_list = optimize_smart_walker(model, observed_rays, uncompensated_parameters_selected, iterations = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98fb28a-ccf5-461b-b8d3-a8af0971c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    observed_rays = model(compensated_parameters_selected)\n",
    "\n",
    "method_dict = {\"smart walker\": optimize_smart_walker, \"brute force\": optimize_brute}\n",
    "method_evaluation_list = []\n",
    "\n",
    "for key, entry in method_dict.items():\n",
    "    mean_best, std_best, mean_progress, std_progress, loss_min_params_tens = evaluate_evaluation_method(entry, model, observed_rays, uncompensated_parameters_selected, offsets_selected, repetitions=2, num_candidates=20000, iterations=100)\n",
    "    method_evaluation_list.append((key, mean_best, std_best, mean_progress, std_progress))\n",
    "\n",
    "    # calculate deviations from target offset\n",
    "    normalized_offsets = (offsets_selected + max_offset) / (max_offset + max_offset)\n",
    "    predicted_offsets = (loss_min_params_tens - uncompensated_parameters_selected[0].squeeze())\n",
    "    normalized_predicted_offsets = (predicted_offsets + max_offset) / (max_offset + max_offset)\n",
    "    rmse = ((normalized_offsets-predicted_offsets)**2).mean().sqrt().item()\n",
    "    print(key, \":\", mean_best, \"±\", std_best, \"RMSE from target offset:\", rmse)\n",
    "    loss_min_params_tens = (uncompensated_parameters_selected + predicted_offsets).swapaxes(0,1)\n",
    "    loss_min_ray_outputs = param_tensor_to_ray_outputs(loss_min_params_tens)\n",
    "    reference_ray_outputs = param_tensor_to_ray_outputs(compensated_parameters_selected.swapaxes(0,1))\n",
    "    compensated_parameters_selected_ray_outputs = param_tensor_to_ray_outputs(compensated_parameters_selected.swapaxes(0,1).repeat_interleave(10, dim=0))\n",
    "    out = compare_with_reference(reference_ray_outputs, loss_min_ray_outputs)\n",
    "    print(\"deviation best to ref\", out[0], \"±\", out[1])\n",
    "    out = compare_with_reference(reference_ray_outputs, compensated_parameters_selected_ray_outputs)\n",
    "    print(\"deviation ref to ref\", out[0], \"±\", out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d099fa3-e97e-43f1-ba79-78a0aad7e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from geomloss import SamplesLoss  # GeomLoss for Sinkhorn distance\n",
    "\n",
    "# Step 1: Create two Gaussian point clouds\n",
    "def create_gaussian_blob(center, cov, num_points=100):\n",
    "    mean = center\n",
    "    cov_matrix = torch.diag(torch.tensor(cov))  # Covariance matrix for Gaussian\n",
    "    distribution = torch.distributions.MultivariateNormal(mean, cov_matrix)\n",
    "    points = distribution.sample((num_points,))\n",
    "    return points\n",
    "\n",
    "# Create two Gaussian blobs\n",
    "blob1 = create_gaussian_blob(center=torch.tensor([0.0, 0.0]), cov=[1.0, 1.0], num_points=100)\n",
    "blob2 = create_gaussian_blob(center=torch.tensor([3.0, 3.0]), cov=[1.0, 1.0], num_points=100)\n",
    "\n",
    "# Step 2: Define the Sinkhorn distance using GeomLoss\n",
    "loss_fn = SamplesLoss(\"sinkhorn\", blur=0.1)  # Sinkhorn distance with regularization\n",
    "\n",
    "# Step 3: Compute the Sinkhorn distance\n",
    "sinkhorn_distance = loss_fn(blob1, blob2)\n",
    "\n",
    "# Print the resulting Sinkhorn distance\n",
    "print(f\"Sinkhorn distance between the two blobs: {sinkhorn_distance.item()}\")\n",
    "\n",
    "# Step 4: (Optional) Visualize the point clouds\n",
    "plt.scatter(blob1[:, 0].cpu(), blob1[:, 1].cpu(), color='red', label='Blob 1', alpha=0.6)\n",
    "plt.scatter(blob2[:, 0].cpu(), blob2[:, 1].cpu(), color='blue', label='Blob 2', alpha=0.6)\n",
    "plt.title(\"2D Gaussian Blobs\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c259ac6-0afd-4e82-9bbf-36a39d0cd3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = SinkhornLoss()\n",
    "sl.loss_fn(out[0], out[1], 'ImagePlane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8916a065-2c8f-4f19-ad9e-ba5783df0286",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (4.905, 4.434))\n",
    "ax = plt.gca()\n",
    "i = 0\n",
    "plot_list = []\n",
    "for key, mean_best, std_best, mean_progress, std_progress in method_evaluation_list:\n",
    "    color = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][i+3]\n",
    "    plt.fill_between(torch.arange(len(mean_progress)), (mean_progress-std_progress).cpu(), (mean_progress+std_progress).cpu(), color=color, alpha=0.2)\n",
    "    plot, = plt.plot(torch.arange(len(mean_progress)), mean_progress.cpu(), alpha = 1., c = color)\n",
    "    plot_list.append(plot)\n",
    "    i = i+1\n",
    "ax.legend(plot_list, [key for key in method_dict.keys()], prop={'size': 11})\n",
    "ax.tick_params(axis='both', which='major', labelsize=11)\n",
    "plt.xlabel('Iteration', fontsize=16)\n",
    "plt.ylabel('MSE (log)', fontsize=16)\n",
    "ax.set_yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../outputs/bl_optimizer_iterations.pdf', bbox_inches='tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4e4a4b-2460-44ab-82fa-da1a5bb75243",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = benchmark.Timer(\n",
    "    stmt='optimize_smart_walker(model, observed_rays, uncompensated_parameters_selected)',\n",
    "    setup='from __main__ import optimize_smart_walker',\n",
    "    globals={'model': model, 'observed_rays': observed_rays, 'uncompensated_parameters_selected': uncompensated_parameters_selected},\n",
    "    num_threads=1,\n",
    "    label='optimize smart walker',\n",
    "    sub_label='optimize smart walker')\n",
    "print(t0.timeit(repetitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4765ab94-0f73-4c31-b52d-b11ae0bfe002",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_observed_rays = observed_rays.squeeze()\n",
    "plot_min_param_rays = model(loss_min_params)\n",
    "fig, ax = plt.subplots(1, plot_observed_rays.shape[0], sharex=True, sharey=True, figsize=(32, 9))\n",
    "with torch.no_grad():\n",
    "    for i in range(plot_observed_rays.shape[0]):\n",
    "        ax[i].plot(model(loss_min_params)[i].cpu())\n",
    "        ax[i].plot(observed_rays.squeeze()[i].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca2dfaf-7a6b-4d4a-a66c-1b0c9f4e2330",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_tensors(loss_min_params[:], uncompensated_parameters_selected[:], engine = engine, compensated_parameters=compensated_parameters_selected[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060356b2-e008-4493-881b-75efef1252dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray_tools.base.transform import Histogram, RayTransformConcat, XYHistogram\n",
    "import tqdm\n",
    "\n",
    "transforms = [\n",
    "        XYHistogram(50, (-10., 10.), (-3., 3.))\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(1,2, sharey=True, squeeze=False)\n",
    "\n",
    "x_simulation_hist_list = []\n",
    "y_simulation_hist_list = []\n",
    "for i in tqdm.trange(2):\n",
    "    out = engine.run(tensor_list_to_param_container_list(loss_min_params), XYHistogram(50, (-10., 10.), (-3., 3.)))\n",
    "    out_simulation = out[-1]['ray_output']['ImagePlane']['0.0']\n",
    "    x_simulation_hist, _ = torch.histogram(out_simulation.x_loc,bins=50, range=[-10, 10])\n",
    "    y_simulation_hist, _ = torch.histogram(out_simulation.y_loc,bins=50, range=[-3, 3])\n",
    "    x_simulation_hist_list.append(x_simulation_hist / 22594.)\n",
    "    y_simulation_hist_list.append(y_simulation_hist / 22594.)\n",
    "    \n",
    "    ax[0, 0].plot(torch.linspace(-10, 10, 50), x_simulation_hist / 22594.)\n",
    "    ax[0, 1].plot(torch.linspace(-3, 3, 50), y_simulation_hist / 22594.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2835c97-20fc-4df7-9f82-e8a0460905bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_min_params.shape\n",
    "t = tensor_list_to_param_container_list(loss_min_params)\n",
    "out = [engine.run(tensor_list_to_param_container_list(loss_min_params), XYHistogram(50, (-10., 10.), (-3., 3.))) for i in tqdm.trange(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dee67c-a53d-48d2-847e-a2dc43d1673a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be920a4b-df8d-4c6a-afd3-ee2860c7ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f93da-f748-4d9a-8cc9-7d83236cd629",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_list = []\n",
    "for i in out:\n",
    "    hist_list.append(torch.vstack([j['ray_output']['ImagePlane']['histogram'].reshape(-1) / 22594. for j in i]))\n",
    "#        plt.plot(j['ray_output']['ImagePlane']['histogram'].reshape(-1) / 22594.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97df58e-a7a2-4e45-a925-63b0bd0d6d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_list_tensor = torch.stack(hist_list)\n",
    "#print(hist_list_tensor.shape)\n",
    "print(\"var\",hist_list_tensor.var(dim=0, correction=0).mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26899f5-568d-4447-af06-fc8786606588",
   "metadata": {},
   "source": [
    "# Import real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2faae3b-c24d-42dc-89fd-7043dd4eaf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_real_hist_data(path = 'datasets/metrix_real_data/2021_march_complete', import_set = ['M03', 'M10', 'M18', 'M22', 'M23', 'M24', 'M25', 'M27', 'M28', 'M29', 'M30', 'M32', 'M33', 'M36',\n",
    "                             'M37', 'M40', 'M41', 'M42', 'M43', 'M44'], check_value_lims=False):\n",
    "    imported_data = import_data(\n",
    "                path,\n",
    "                import_set,\n",
    "                [0.],\n",
    "                params(),\n",
    "                check_value_lims=check_value_lims,\n",
    "            )\n",
    "    xy_hist = XYHistogram(50, (-10., 10.), (-3., 3.))\n",
    "    \n",
    "    real_data_list = []\n",
    "    for i in range(len(imported_data)):\n",
    "        real_data_list.append(xy_hist(imported_data[i]['ray_output']['ImagePlane']))\n",
    "    \n",
    "    real_data_point_cloud_list = []\n",
    "    for i in range(len(imported_data)):\n",
    "        real_data_point_cloud_list.append(imported_data[i])\n",
    "    \n",
    "    real_data_tensor = torch.stack([real_data_list[i][0.0]['histogram'] for i in range(len(real_data_list))])\n",
    "    real_data_tensor_normalized = surrogate_engine.model.standardizer(real_data_tensor)\n",
    "    \n",
    "    uncompensated_parameters_list = []\n",
    "    for i in range(len(imported_data)):\n",
    "        uncompensated_entry = torch.tensor([value.get_value() for value in Plot.normalize_parameters(imported_data[i]['param_container_dict'], params()).values()])\n",
    "        uncompensated_parameters_list.append(uncompensated_entry)\n",
    "    uncompensated_parameters = torch.stack(uncompensated_parameters_list)\n",
    "    \n",
    "    observed_rays = real_data_tensor_normalized.flatten(start_dim=1).unsqueeze(1).float().to(model.device)\n",
    "    uncompensated_parameters = uncompensated_parameters.unsqueeze(1).float().to(model.device)\n",
    "    observed_rays_point_cloud = ray_output_to_tensor(real_data_point_cloud_list, 'ImagePlane')\n",
    "    return observed_rays, uncompensated_parameters, observed_rays_point_cloud\n",
    "observed_rays_real, uncompensated_parameters_real, observed_rays_point_cloud = import_real_hist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58b100-897d-45a2-aa64-73361f5b6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_min_params = optimize_smart_walker(model, observed_rays_real, uncompensated_parameters_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec1683-db55-411e-94f5-c232488db214",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device('cpu')\n",
    "pc = [tensor_to_param_container(loss_min_params[i].cpu()) for i in range(loss_min_params.shape[0])]\n",
    "Plot.plot_engines_comparison(engine, surrogate_engine, pc[:8], MultiLayer([0.]), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2c876-88bd-41e1-a73c-088c9b82b9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2f2b8-bac3-49ac-98eb-3d8fc157054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_tensors(loss_min_params[:], uncompensated_parameters_selected[:], compensated_parameters=compensated_parameters_selected[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccf28d6-559e-4c95-bc95-360d71a6eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_params = torch.vstack(10*[loss_min_params[1]])\n",
    "a = repeated_params.clone()\n",
    "b = repeated_params.clone()\n",
    "c = repeated_params.clone()\n",
    "for i, ten in enumerate(a):\n",
    "    ten[-1]=0.5+0.1*i\n",
    "    ten[-2]=0.5\n",
    "for i, ten in enumerate(b):\n",
    "    ten[-2]=0.5+0.1*i\n",
    "    ten[-1]=0.5\n",
    "for i, ten in enumerate(c):\n",
    "    ten[-1]=0.5\n",
    "    ten[-2]=0.5#+0.005*i\n",
    "plot_param_tensors(a[:3], b[:3], compensated_parameters=c[:3])\n",
    "#print(repeated_params)\n",
    "#plot_param_tensors(loss_min_params[:], uncompensated_parameters_selected[:], compensated_parameters=compensated_parameters_selected[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a87724d-4ca2-433d-9957-e4f8ae902631",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_min_params.shape, uncompensated_parameters_selected.shape, compensated_parameters_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0e49fe-5a57-4edf-a8f4-fab2f552d124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ef0d19-7c06-4a60-acc3-b5114c15cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_comparison_plot = Plot.plot_param_comparison(\n",
    "    predicted_params=tensor_list_to_param_container_list(loss_min_params.squeeze().unsqueeze(0)),\n",
    "    epoch=42,\n",
    "    training_samples_count=len(observed_rays),\n",
    "    search_space=params(),\n",
    "    real_params=tensor_list_to_param_container_list(compensated_parameters_selected)[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217c54c-b558-41f1-9e7a-66b78f1bdc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_comparison_plot = Plot.plot_param_comparison(\n",
    "    predicted_params=tensor_to_param_container(offsets_selected.squeeze()),\n",
    "    epoch=42,\n",
    "    training_samples_count=len(observed_rays),\n",
    "    search_space=RayOptimization.limited_search_space(params(), RandomGenerator(42), max_deviation=max_offset),\n",
    "    real_params=tensor_list_to_param_container_list(loss_min_params[0] - compensated_parameters_selected.squeeze())[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c91816-b241-4f86-ba22-b4f610b91e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import transforms\n",
    "import numpy as np\n",
    "from matplotlib.layout_engine import ConstrainedLayoutEngine, TightLayoutEngine\n",
    "from matplotlib.ticker import NullLocator\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "rs = np.random.RandomState(11)\n",
    "x = rs.gamma(4, size=1000)\n",
    "y = -.5 * x + rs.normal(size=1000)\n",
    "x = x / 4  -1\n",
    "y = y/4 +1\n",
    "\n",
    "\n",
    "def scatter_hist(x, y, ax, ax_histx, ax_histy):\n",
    "    xlim_min, xlim_max, ylim_min, ylim_max = -2, 2, -2, 2\n",
    "    # no labels\n",
    "    ax_histx.tick_params(axis=\"x\", labelbottom=False)\n",
    "    ax_histy.tick_params(axis=\"y\", labelleft=False)\n",
    "\n",
    "    # the scatter plot:\n",
    "    color = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][1]\n",
    "    ax.scatter(\n",
    "    x,\n",
    "    y,\n",
    "    s=2.0,\n",
    "    alpha=0.5,\n",
    "    linewidths=0.4,\n",
    "    color=color\n",
    "    )\n",
    "    ax.set_xlim(\n",
    "    Plot.scale_interval(\n",
    "        xlim_min, xlim_max, 1.2\n",
    "    )\n",
    ")\n",
    "    ax.set_ylim(\n",
    "        Plot.scale_interval(\n",
    "            ylim_min, ylim_max, 1.2\n",
    "        )\n",
    "    )\n",
    "    ax.tick_params(axis=\"both\", length=0.0)\n",
    "    ax.grid(linestyle=\"dashed\", alpha=0.5)\n",
    "    ax.xaxis.set_major_locator(NullLocator())\n",
    "    ax.yaxis.set_major_locator(NullLocator())\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter(\"%.1f\"))\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.1f\"))\n",
    "    \n",
    "    ax.set_xticks((xlim_min, xlim_max))\n",
    "    ax.set_yticks((ylim_min, ylim_max))\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "    # now determine nice limits by hand:\n",
    "    binwidth = 0.25\n",
    "    xymax = max(np.max(np.abs(x)), np.max(np.abs(y)))\n",
    "    lim = (int(xymax/binwidth) + 1) * binwidth\n",
    "\n",
    "    bins = np.arange(-lim, lim + binwidth, binwidth)\n",
    "    #ax_histx.hist(x, bins=bins, color=color)\n",
    "    x_simulation_hist, _ = torch.histogram(torch.from_numpy(x),bins=50, range=[-2, 2])\n",
    "    ax_histx.plot(torch.linspace(-2, 2, 50), x_simulation_hist, color=color)\n",
    "    ax_histx.set_yticklabels([])\n",
    "    #ax_histy.hist(y, bins=bins, orientation='horizontal', color=color)\n",
    "    y_simulation_hist, _ = torch.histogram(torch.from_numpy(y),bins=50, range=[-2, 2])\n",
    "    ax_histy.plot(y_simulation_hist, torch.linspace(-2, 2, 50), color=color)\n",
    "    ax_histy.set_xticklabels([])\n",
    "\n",
    "\n",
    "# Create a Figure, which doesn't have to be square.\n",
    "fig = plt.figure(layout='constrained')\n",
    "# Create the main Axes, leaving 25% of the figure space at the top and on the\n",
    "# right to position marginals.\n",
    "ax = fig.add_gridspec(top=0.75, right=0.75).subplots()\n",
    "# The main Axes' aspect can be fixed.\n",
    "ax.set(aspect=1)\n",
    "# Create marginal Axes, which have 25% of the size of the main Axes.  Note that\n",
    "# the inset Axes are positioned *outside* (on the right and the top) of the\n",
    "# main Axes, by specifying axes coordinates greater than 1.  Axes coordinates\n",
    "# less than 0 would likewise specify positions on the left and the bottom of\n",
    "# the main Axes.\n",
    "ax_histx = ax.inset_axes([0, 1.05, 1, 0.25], sharex=ax)\n",
    "ax_histy = ax.inset_axes([1.05, 0, 0.25, 1], sharey=ax)\n",
    "# Draw the scatter plot and marginals.\n",
    "scatter_hist(x, y, ax, ax_histx, ax_histy)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a99514-298b-46ac-930e-172fd0d86950",
   "metadata": {},
   "source": [
    "# Evotorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224f1d6-2833-418a-848c-3f26d28e4bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evotorch import Problem\n",
    "from evotorch.algorithms import SNES\n",
    "from evotorch.logging import StdOutLogger\n",
    "\n",
    "def norm(x: torch.Tensor) -> torch.Tensor:\n",
    "  return torch.linalg.norm(x, dim=-1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    observed_rays = model(compensated_parameters_selected)\n",
    "uncompensated_parameters = uncompensated_parameters_selected\n",
    "def loss(x: torch.Tensor) -> torch.Tensor:\n",
    "    with torch.no_grad():\n",
    "        tensor_sum = x + uncompensated_parameters\n",
    "        compensated_rays = model(tensor_sum, clone_output=True)\n",
    "        compensated_rays = compensated_rays.flatten(start_dim=2)\n",
    "        loss_orig = ((compensated_rays - observed_rays) ** 2).mean(0).mean(-1)\n",
    "    return loss_orig\n",
    "\n",
    "problem = Problem(\n",
    "  \"min\",\n",
    "  loss,\n",
    "  initial_bounds=(0., 1.),\n",
    "  solution_length=34,\n",
    "  vectorized=True,\n",
    "  device=\"cuda\",  # Enable for GPU support\n",
    ")\n",
    "\n",
    "searcher = SNES(problem, popsize=1000, stdev_init=0.3)\n",
    "_ = StdOutLogger(searcher, interval=1000)\n",
    "\n",
    "searcher.run(num_generations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abffe766-3b6c-476c-a4bf-d22bd55a9245",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_discovered_solution = searcher.status[\"pop_best\"]\n",
    "print(best_discovered_solution.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bef591-1594-40af-bd3c-e862a9603f56",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a98980-c87c-4bd4-a775-e92dc0062c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "x = torch.rand((batch_size, 36), requires_grad=True, device=model.device)\n",
    "optimizer = torch.optim.SGD([x], lr=0.01)  # Adjust the learning rate as needed\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "num_epochs = 1000  # Number of iterations\n",
    "uncompensated_parameters = uncompensated_parameters_selected\n",
    "#with torch.no_grad():\n",
    "observed_rays = model(compensated_parameters_selected)\n",
    "\n",
    "def function_to_minimize(x):\n",
    "    tensor_sum = x + uncompensated_parameters\n",
    "    compensated_rays = model(tensor_sum)\n",
    "    compensated_rays = compensated_rays.flatten(start_dim=2)\n",
    "    loss_orig = ((compensated_rays - observed_rays) ** 2).mean(0).mean(-1)\n",
    "    return loss_orig\n",
    "\n",
    "pbar = tqdm.trange(num_epochs)\n",
    "for epoch in pbar:\n",
    "    optimizer.zero_grad()  # Clear the gradients from the previous step\n",
    "    \n",
    "    output = function_to_minimize(x.detach())  # Compute the function's output\n",
    "    loss = output.mean()  # Compute the mean loss for this batch\n",
    "    \n",
    "    loss.backward(retain_graph=True)  # Backpropagate to compute the gradients\n",
    "    optimizer.step()  # Update the parameters with SGD\n",
    "    \n",
    "    # Optionally print the loss to monitor progress\n",
    "    if epoch % 100 == 0:\n",
    "        pbar.set_postfix({\"loss\": loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d053b4-e567-438c-bf48-bd517380423a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
