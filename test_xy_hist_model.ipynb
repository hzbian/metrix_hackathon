{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbf68af-b5df-4ceb-aac1-ab31ad256ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray_nn.nn.xy_hist_data_models import MetrixXYHistSurrogate\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange, tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f29c39f-ff59-40ca-8568-062f08208a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(module=MetrixXYHistSurrogate, checkpoint_path: str=\"outputs/xy_hist/muqyzwbp/checkpoints/epoch=8739-step=106732880.ckpt\"):\n",
    "    model = module.load_from_checkpoint(checkpoint_path)\n",
    "    model.to(torch.device('cpu'))\n",
    "    model.compile()\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_model()\n",
    "std_backward = model.stadardizer.backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d7fccd-8cc1-47bc-9c80-27c41872fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(torch.ones((1, 34))*0.5).reshape(2, -1)\n",
    "    print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000cae83-0f66-4a30-847d-b1df96afb088",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(torch.linspace(-10, 10, 50), std_backward(out[0]))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dee18f-6edb-4cc0-85e0-5130d590fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.linspace(-3, 3, 50), std_backward(out[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db973a-ae52-4e45-927d-192da1e0f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray_nn.data.transform import Select\n",
    "from ray_nn.nn.xy_hist_data_models import StandardizeXYHist\n",
    "from ray_tools.simulation.torch_datasets import BalancedMemoryDataset, MemoryDataset, RayDataset\n",
    "import glob\n",
    "from datasets.metrix_simulation.config_ray_emergency_surrogate import PARAM_CONTAINER_FUNC as params\n",
    "h5_files = list(glob.iglob('datasets/metrix_simulation/ray_emergency_surrogate/50+50_data_raw_*.h5')) # ['datasets/metrix_simulation/ray_emergency_surrogate/49+50_data_raw_0.h5']\n",
    "\n",
    "load_len = 1000\n",
    "\n",
    "dataset = RayDataset(h5_files=h5_files,\n",
    "                        sub_groups=['1e5/params',\n",
    "                                    '1e5/histogram', '1e5/n_rays'], transform=Select(keys=['1e5/params', '1e5/histogram', '1e5/n_rays'], search_space=params(), non_dict_transform={'1e5/histogram': StandardizeXYHist()}))\n",
    "\n",
    "memory_dataset = MemoryDataset(dataset=dataset, load_len=load_len)#, min_n_rays=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765345f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,z in enumerate(memory_dataset):\n",
    "    x = z[0]\n",
    "    y = z[1]\n",
    "    with torch.no_grad():\n",
    "        if y.sum() > 5:\n",
    "            print(i, x.shape, y.shape)\n",
    "            print(y.sum())\n",
    "            out = model(x).reshape(2, -1)\n",
    "            plt.plot(y[0].flatten())\n",
    "            plt.plot(out[0].detach().cpu())\n",
    "            print(x)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03c0f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(memory_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e841e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tu in memory_dataset:\n",
    "#    x = tu[0]\n",
    "#    y = tu[1]\n",
    "    #print(x.shape)\n",
    "    #print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10036aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8c8188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray_nn.data.lightning_data_module import DefaultDataModule\n",
    "from ray_nn.nn.xy_hist_data_models import MetrixXYHistSurrogate\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "import glob\n",
    "from ray_nn.data.transform import Select\n",
    "from ray_nn.nn.xy_hist_data_models import StandardizeXYHist\n",
    "from ray_tools.simulation.torch_datasets import BalancedMemoryDataset, MemoryDataset, RayDataset\n",
    "import glob\n",
    "from datasets.metrix_simulation.config_ray_emergency_surrogate import PARAM_CONTAINER_FUNC as params\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "load_len: int | None = None\n",
    "dataset_normalize_outputs = True\n",
    "h5_files = list(glob.iglob('datasets/metrix_simulation/ray_emergency_surrogate/50+50_data_raw_*.h5')) # ['datasets/metrix_simulation/ray_emergency_surrogate/49+50_data_raw_0.h5']\n",
    "dataset = RayDataset(h5_files=h5_files,\n",
    "                    sub_groups=['1e5/params',\n",
    "                                '1e5/histogram', '1e5/n_rays'], transform=Select(keys=['1e5/params', '1e5/histogram', '1e5/n_rays'], search_space=params(), non_dict_transform={'1e5/histogram': StandardizeXYHist()}))\n",
    "\n",
    "memory_dataset = BalancedMemoryDataset(dataset=dataset, load_len=load_len, min_n_rays=500)\n",
    "datamodule = DefaultDataModule(dataset=memory_dataset, num_workers=4)\n",
    "datamodule.prepare_data()\n",
    "model = MetrixXYHistSurrogate(dataset_length=load_len, dataset_normalize_outputs=dataset_normalize_outputs)\n",
    "wandb_logger = WandbLogger(name=\"ref_bal_500_sch_.999_test\", project=\"xy_hist\", save_dir='outputs')\n",
    "#wandb_logger = None\n",
    "datamodule.setup(stage=\"test\")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "trainer = L.Trainer(max_epochs=10000, logger=wandb_logger, log_every_n_steps=100, check_val_every_n_epoch=1, callbacks=[lr_monitor])\n",
    "trainer.init_module()\n",
    "\n",
    "trainer.test(datamodule=datamodule, ckpt_path='outputs/xy_hist/pd388nv8/checkpoints/epoch=755-step=147239316.ckpt', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4659ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(datamodule=datamodule, ckpt_path='outputs/xy_hist/pd388nv8/checkpoints/epoch=755-step=147239316.ckpt', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3058afc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
