{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab8113-e0e8-44e6-a38c-a7889f640d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ray_optim.plot import Plot\n",
    "%matplotlib inline\n",
    "from ray_nn.nn.xy_hist_data_models import MetrixXYHistSurrogate, StandardizeXYHist, HistSurrogateEngine\n",
    "from ray_tools.base.backend import RayBackendDockerRAYUI\n",
    "from ray_tools.base.transform import MultiLayer\n",
    "from ray_nn.data.lightning_data_module import DefaultDataModule\n",
    "from datasets.metrix_simulation.config_ray_emergency_surrogate import PARAM_CONTAINER_FUNC as params\n",
    "from datasets.metrix_simulation.config_ray_emergency_surrogate import TRANSFORMS as cfg_transforms\n",
    "from ray_tools.base.parameter import NumericalParameter, NumericalOutputParameter, RayParameterContainer\n",
    "from ray_tools.simulation.torch_datasets import BalancedMemoryDataset, MemoryDataset, RayDataset\n",
    "from sub_projects.ray_optimization.utils import ray_output_to_tensor\n",
    "from sub_projects.ray_optimization.ray_optimization import RayOptimization\n",
    "from ray_optim.ray_optimizer import RayOptimizer\n",
    "from ray_tools.base.engine import RayEngine\n",
    "from ray_tools.base.utils import RandomGenerator\n",
    "from sub_projects.ray_optimization.real_data import import_data\n",
    "from ray_tools.base.transform import XYHistogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe67c8a6-0a58-49d5-8c68-a6c129ca6eb2",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b976aa19-e83f-4416-b03f-7c922b9e3de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_param_container(ten):\n",
    "    param_dict = {}\n",
    "    for i, (label, entry) in enumerate(params().items()):\n",
    "        if label == 'U41_318eV.numberRays':\n",
    "            param_dict[label] = entry\n",
    "        else:\n",
    "            value = ten[i-1]*(entry.value_lims[1]-entry.value_lims[0])+entry.value_lims[0]\n",
    "            param_dict[label] = NumericalParameter(value.item())\n",
    "            if value.item() < entry.value_lims[0] or value.item() > entry.value_lims[1]:\n",
    "                if value.item() < entry.value_lims[0]:\n",
    "                    value = torch.ones_like(value) * entry.value_lims[0]\n",
    "                elif value.item() > entry.value_lims[1]:\n",
    "                    value = torch.ones_like(value) * entry.value_lims[1]\n",
    "                #raise Exception(\"Out of range. Minimum was {}, maximum {} but value {}. Tensor value was {}.\".format(entry.value_lims[0], entry.value_lims[1], value.item(), ten[i-1].item()))\n",
    "    return RayParameterContainer(param_dict)\n",
    "def mse_engines_comparison(engine, surrogate_engine, param_container_list: list[RayParameterContainer], transforms):\n",
    "    out = engine.run(param_container_list, transforms)\n",
    "    out_surrogate = surrogate_engine.run(param_container_list, transforms)\n",
    "    std_backward = surrogate_engine.model.standardizer.destandardize\n",
    "    x_simulation_hist_list = []\n",
    "    y_simulation_hist_list = []\n",
    "    mse_list = []\n",
    "    for i in range(len(out_surrogate)):\n",
    "        surrogate_hist = out_surrogate[i]['ray_output']['ImagePlane']['xy_hist']\n",
    "        out_simulation = out[i]['ray_output']['ImagePlane']['0.0']\n",
    "        x_simulation_hist, _ = torch.histogram(out_simulation.x_loc,bins=50, range=[-10, 10])\n",
    "        x_simulation_hist_list.append(x_simulation_hist)\n",
    "        y_simulation_hist, _ = torch.histogram(out_simulation.y_loc,bins=50, range=[-3, 3])\n",
    "        y_simulation_hist_list.append(y_simulation_hist)\n",
    "        mse = ((torch.stack([std_backward(surrogate_hist.x_loc), std_backward(surrogate_hist.y_loc)]) - torch.stack([x_simulation_hist, y_simulation_hist]))**2).mean()\n",
    "        mse_list.append(mse)\n",
    "    return torch.stack(mse_list), x_simulation_hist_list, y_simulation_hist_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b643820-f6e9-49cb-97e2-6a96f940fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = RayEngine(rml_basefile='rml_src/METRIX_U41_G1_H1_318eV_PS_MLearn_1.15.rml',\n",
    "                                exported_planes=[\"ImagePlane\"],\n",
    "                                ray_backend=RayBackendDockerRAYUI(docker_image='ray-ui-service',\n",
    "                                                                  docker_container_name='ray-ui-service-test',\n",
    "                                                                  dockerfile_path='ray_docker/rayui',\n",
    "                                                                  ray_workdir='/dev/shm/ray-workdir',\n",
    "                                                                  verbose=False),\n",
    "                                num_workers=-1,\n",
    "                                as_generator=False)\n",
    "surrogate_engine = HistSurrogateEngine(checkpoint_path=\"outputs/xy_hist/i7sryekx/checkpoints/epoch=174-step=42782950.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7763be-2106-4558-8b5c-33224786fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot.plot_engines_comparison(engine, surrogate_engine, [tensor_to_param_container(torch.ones((34))*0.5)], MultiLayer([0.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4318fe85-2d93-4312-ac5a-b089c8f9c707",
   "metadata": {},
   "source": [
    "# Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf51d90-a077-4aea-98dd-d88b38fc077f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_len: int | None = 10000\n",
    "h5_files = list(glob.iglob('datasets/metrix_simulation/ray_emergency_surrogate/data_raw_*.h5'))\n",
    "dataset = RayDataset(h5_files=h5_files,\n",
    "                        sub_groups=['1e5/params',\n",
    "                                    '1e5/ray_output/ImagePlane/histogram', '1e5/ray_output/ImagePlane/n_rays'], transform=Select(keys=['1e5/params', '1e5/ray_output/ImagePlane/histogram', '1e5/ray_output/ImagePlane/n_rays'], search_space=params(), non_dict_transform={'1e5/ray_output/ImagePlane/histogram': surrogate_engine.model.standardizer}))\n",
    "\n",
    "\n",
    "bal_memory_dataset = BalancedMemoryDataset(dataset=dataset, load_len=load_len, min_n_rays=500)\n",
    "memory_dataset = MemoryDataset(dataset=dataset, load_len=load_len)\n",
    "datamodule = DefaultDataModule(dataset=bal_memory_dataset, num_workers=4)\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup(stage=\"test\")\n",
    "test_dl = datamodule.test_dataloader()\n",
    "\n",
    "unbal_datamodule = DefaultDataModule(dataset=memory_dataset, num_workers=4)\n",
    "unbal_datamodule.prepare_data()\n",
    "unbal_datamodule.setup(stage=\"test\")\n",
    "unbal_test_dl = unbal_datamodule.test_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98253db-b210-4ab2-983f-40c050995119",
   "metadata": {},
   "source": [
    "## Maximum distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b4e764-e7da-4764-9e8c-a66a8472e46f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "value_list = []\n",
    "params_list = []\n",
    "\n",
    "for i in tqdm.tqdm(unbal_test_dl):\n",
    "    biggest = i[1].flatten(start_dim=1)\n",
    "    biggest, _ = i[1].flatten(start_dim=1).max(dim=1)\n",
    "    mask = biggest > 0.8\n",
    "    value_list.append(biggest[mask])\n",
    "    params_list.append(i[0][mask])\n",
    "value_tensor = torch.cat(value_list)\n",
    "params_tensor = torch.cat(params_list)\n",
    "\n",
    "torch.save(value_tensor, 'outputs/values.pt')\n",
    "torch.save(params_tensor, 'outputs/params.pt')\n",
    "plt.hist(value_tensor)\n",
    "plt.savefig('outputs/max_dist_hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de822f-7b2f-4b1b-8ce3-5075f5de708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_tensor = torch.load('outputs/values.pt')\n",
    "params_tensor = torch.load('outputs/params.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cb59fd-09a9-4d71-9f60-a35e971980d5",
   "metadata": {},
   "source": [
    "# Special sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a67b85-035a-4433-b00f-80af733a4479",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/special_sample_168_selected.pkl\", \"rb\") as f:\n",
    "    special_sample = pickle.load(f, fix_imports=True, encoding='ASCII', errors='strict', buffers=None)\n",
    "observed_params = special_sample.uncompensated_parameters\n",
    "\n",
    "for param_container in observed_params:\n",
    "    for label in ['ImagePlane.translationXerror', 'ImagePlane.translationYerror', 'ImagePlane.translationZerror']:\n",
    "        if label in list(param_container.keys()):\n",
    "            del param_container[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f574994c-891f-4241-8ebc-69923812263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(observed_params)\n",
    "Plot.plot_engines_comparison(engine, surrogate_engine, observed_params[:5], MultiLayer([0.]), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aedafb7-548b-47ee-bdb1-a33c346eda44",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncompensated_parameters = [elem.clone() for elem in special_sample.uncompensated_parameters]\n",
    "for elem in uncompensated_parameters:\n",
    "    elem.perturb(special_sample.target_params)\n",
    "uncompensated_parameters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903329a4-b9af-4627-a406-8d93a8b058f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot.plot_engines_comparison(engine, surrogate_engine, uncompensated_parameters, MultiLayer([0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f251daa-c4f3-4461-af8d-37f6522f99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_comparison, x_simulation_hist, y_simulation_hist = mse_engines_comparison(engine, surrogate_engine, uncompensated_parameters[:5], MultiLayer([0.]))\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "for hist in x_simulation_hist:\n",
    "    ax[0].plot(hist, alpha=0.3)\n",
    "for hist in y_simulation_hist:\n",
    "    ax[1].plot(hist, alpha=0.3)\n",
    "ax[2].hist(mse_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a5863a-6470-42a4-9f13-3f7b5abe0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_loc_list = []\n",
    "good_param_list = []\n",
    "batch_size = 5000\n",
    "for i in tqdm.trange(15000//batch_size):\n",
    "    param_container = [tensor_to_param_container(torch.rand((34,))) for _ in range(batch_size)]\n",
    "    surrogate_out = surrogate_engine.run(param_container, MultiLayer([0.]))\n",
    "    for j in range(len(param_container)):\n",
    "        output = surrogate_out[j]['ray_output']['ImagePlane']['xy_hist']\n",
    "        if output.x_loc.sum() > 0.5:\n",
    "            x_loc_list.append(output.x_loc.sum())\n",
    "            good_param_list.append(param_container[j])\n",
    "\n",
    "observed_containers_tensor = torch.vstack([surrogate_engine.select({\"1e5/params\":param_container})[0] for param_container in observed_params])\n",
    "good_containers_tensor = torch.vstack([surrogate_engine.select({\"1e5/params\":param_container})[0] for param_container in good_param_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a886aeb-f0b4-4971-84e8-4b2b3662ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "for i in range(good_containers_tensor.shape[0]):\n",
    "    plt.plot(good_containers_tensor[i], c = 'blue', alpha=0.1)\n",
    "for i in range(observed_containers_tensor.shape[0]):\n",
    "    plt.plot(observed_containers_tensor[i], alpha=0.8)\n",
    "plt.legend([\"special\", \"good\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418cb63a-b773-4aab-854b-dec4755ccc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = value_tensor > 0.44\n",
    "out = ((params_tensor - observed_containers_tensor[0].unsqueeze(0))**2)/2.\n",
    "out = out.mean(dim=1)\n",
    "out_sorted, indices = torch.sort(out)\n",
    "#part_indices = indices[:5]\n",
    "#print(part_indices.shape)\n",
    "#min_arg = out.argmin()\n",
    "#plt.hist(out.mean(dim=1))\n",
    "#plt.plot(params_tensor[min_arg])\n",
    "#plt.plot(observed_containers_tensor[0])\n",
    "for i in indices[:1]:\n",
    "    plt.plot(params_tensor[i])\n",
    "Plot.plot_engines_comparison(engine, surrogate_engine, [tensor_to_param_container(params_tensor[min_arg]) for min_arg in indices[:1]], MultiLayer([0.]), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43f2ae6-d74d-40db-b064-a727184380eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#surrogate_engine.run(observed_params)\n",
    "model = MetrixXYHistSurrogate.load_from_checkpoint(\"outputs/xy_hist/i7sryekx_copy/checkpoints/epoch=186-step=45716638.ckpt\")\n",
    "select = Select(keys=['1e5/params'], omit_ray_params=['U41_318eV.numberRays'], search_space=params(), non_dict_transform={'1e5/ray_output/ImagePlane/histogram': model.standardizer})\n",
    "param_containers_tensor = torch.vstack([select({\"1e5/params\":param_container})[0] for param_container in observed_params])\n",
    "with torch.no_grad():\n",
    "    out_model = model(param_containers_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e4311-ab69-4692-a340-5f0cb3342039",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = {\"ImagePlane\": transform for transform in cfg_transforms}\n",
    "out_engine = engine.run(observed_params, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636cd240-dc8b-48bf-937c-7c39caa881fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_simulations = surrogate_engine.model.standardizer(torch.vstack([element['ray_output']['ImagePlane']['histogram'].flatten(start_dim=0) for element in out_engine]))\n",
    "a = ((standardized_simulations - out_model)**2).mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7500019-8d32-4055-b085-3311b7bdeb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933e278-11bf-4216-bdb2-e6643ed5d668",
   "metadata": {},
   "source": [
    "# Good params vs. bad params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7513437-7f9c-44b0-8793-e9549a488ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = []\n",
    "num_rays_list = []\n",
    "for i in tqdm.tqdm(memory_dataset):\n",
    "    params_list.append(i[0])\n",
    "    num_rays_list.append(i[2])\n",
    "params_tensor = torch.vstack(params_list)\n",
    "num_rays_tensor= torch.vstack(num_rays_list)\n",
    "plt.hist(torch.tensor(num_rays_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f571f-4de1-43c0-b71e-df26e91d5d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest = torch.tensor(num_rays_list).argmax()\n",
    "test_parameters = memory_dataset[biggest][0]\n",
    "param_container_list = [tensor_to_param_container(test_parameters)]\n",
    "\n",
    "fig, ax = plt.subplots(1,2, sharey=True, squeeze=False)\n",
    "\n",
    "for i in tqdm.trange(20):\n",
    "    out = engine.run(param_container_list, MultiLayer([0.]))\n",
    "    out_simulation = out[-1]['ray_output']['ImagePlane']['0.0']\n",
    "    x_simulation_hist, _ = torch.histogram(out_simulation.x_loc,bins=50, range=[-10, 10])\n",
    "    y_simulation_hist, _ = torch.histogram(out_simulation.y_loc,bins=50, range=[-3, 3])\n",
    "    ax[0, 0].plot(torch.linspace(-10, 10, 50), x_simulation_hist)\n",
    "    ax[0, 1].plot(torch.linspace(-3, 3, 50), y_simulation_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8463884f-efac-4924-acb9-bcf050cc3494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "mask = num_rays_tensor > 100.\n",
    "data_tensor = params_tensor[mask.flatten()]\n",
    "data_tensor = data_tensor[:,:4]\n",
    "class_tensor = num_rays_tensor[mask]\n",
    "\n",
    "data_np = data_tensor.numpy()\n",
    "class_np = class_tensor.numpy().flatten()\n",
    "\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2)\n",
    "umap_embedding = umap_model.fit_transform(data_np)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(umap_embedding[:, 0], umap_embedding[:, 1], c=class_np, cmap='Spectral', s=5)\n",
    "plt.colorbar(scatter)\n",
    "plt.title('UMAP projection of the dataset')\n",
    "plt.xlabel('UMAP 1')\n",
    "plt.ylabel('UMAP 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0bf724-e188-4443-b1c9-bcc265cb445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne_model = TSNE(n_components=2, perplexity=30, learning_rate=200, max_iter=1000)\n",
    "tsne_embedding = tsne_model.fit_transform(data_np)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(tsne_embedding[:, 0], tsne_embedding[:, 1], c=class_np, cmap='Spectral', s=5)\n",
    "plt.colorbar(scatter)\n",
    "plt.title('t-SNE projection of the dataset')\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a61f44c-0ba3-4eec-97c2-31fdeac4cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from ray_nn.nn.xy_hist_data_models import MetrixXYHistSurrogate, StandardizeXYHist\n",
    "from ray_tools.simulation.torch_datasets import MemoryDataset, RayDataset\n",
    "from datasets.metrix_simulation.config_ray_emergency_surrogate import PARAM_CONTAINER_FUNC as params\n",
    "from torch.utils.data import DataLoader\n",
    "from ray_nn.data.transform import Select\n",
    "\n",
    "\n",
    "model = MetrixXYHistSurrogate.load_from_checkpoint(\"outputs/xy_hist/i7sryekx/checkpoints/epoch=174-step=42782950.ckpt\")\n",
    "model.to(torch.device('cpu'))\n",
    "model.compile()\n",
    "model.eval()\n",
    "\n",
    "load_len: int | None = None\n",
    "h5_files = list(glob.iglob('datasets/metrix_simulation/ray_emergency_surrogate/selected/data_raw_*.h5'))\n",
    "dataset = RayDataset(h5_files=h5_files,\n",
    "                        sub_groups=['1e5/params',\n",
    "                                    '1e5/ray_output/ImagePlane/histogram', '1e5/ray_output/ImagePlane/n_rays'], transform=Select(keys=['1e5/params', '1e5/ray_output/ImagePlane/histogram', '1e5/ray_output/ImagePlane/n_rays'], search_space=params(), non_dict_transform={'1e5/ray_output/ImagePlane/histogram': model.standardizer}))\n",
    "\n",
    "\n",
    "memory_dataset = MemoryDataset(dataset=dataset, load_len=load_len)\n",
    "\n",
    "train_dataloader = DataLoader(memory_dataset, batch_size=2048, shuffle=False, num_workers=0)\n",
    "\n",
    "errors_list = []\n",
    "with torch.no_grad():\n",
    "    for par_input, label, _ in tqdm.tqdm(train_dataloader):\n",
    "        out = model(par_input)\n",
    "        label = label.flatten(start_dim=1)\n",
    "        b = ((label - out)**2).mean(dim=1)\n",
    "        errors_list.append(b)\n",
    "errors_tensor = torch.cat(errors_list)\n",
    "\n",
    "plt.hist(errors_tensor)\n",
    "plt.savefig('outputs/dataset_errors_hist.png')\n",
    "torch.save(errors_tensor, 'outputs/dataset_errors.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19d0003-49c6-4b29-8ae4-3a0e3eadc779",
   "metadata": {},
   "source": [
    "# Look with model for new sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b9fca-1631-4d84-891e-3a183812837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        model_orig = MetrixXYHistSurrogate.load_from_checkpoint(\"outputs/xy_hist/i7sryekx/checkpoints/epoch=174-step=42782950.ckpt\")\n",
    "        model_orig = model_orig.to('cuda')\n",
    "        model_orig.compile()\n",
    "        model_orig.eval()\n",
    "        self.x_factor = 0./20.\n",
    "        self.y_factor = 0./4.\n",
    "        self.model_orig = model_orig\n",
    "        self.device = model_orig.device\n",
    "    def __call__(self, x, clone_output=False):\n",
    "        output = self.model_orig(x[..., :34])\n",
    "        #print(\"Original Histogram Batch:\")\n",
    "        #print(output.shape)\n",
    "        #output = output.view(*(output.size()[:-1]), 2, -1)\n",
    "        if clone_output:\n",
    "            output = output.clone()\n",
    "        translation_x = x[..., -2]\n",
    "        translation_y = x[..., -1]\n",
    "        #print(\"output\", output.shape)\n",
    "        #print(\"tx\", translation_x.shape)\n",
    "        ##output[..., 0, :] = Model.batch_translate_histograms(output[..., 0, :], translation_x*self.x_factor*0.5+0.5)\n",
    "        ##output[..., 1, :] = Model.batch_translate_histograms(output[..., 1, :], translation_y*self.y_factor*0.5+0.5)\n",
    "        #print(\"\\nTranslated Histogram Batch:\")\n",
    "        #print(output.flatten(start_dim=-2).shape)\n",
    "        \n",
    "        return output#output.flatten(start_dim=-2)\n",
    "        \n",
    "    @staticmethod\n",
    "    def batch_translate_histograms(hist_batch, shift_tensors):\n",
    "        #print(hist_batch.shape, shift_tensors.shape)\n",
    "        \"\"\"\n",
    "        Translate a batch of histograms in the x-direction based on the batch of shift tensors.\n",
    "        The histograms have defined ranges on both x and y axes.\n",
    "    \n",
    "        Parameters:\n",
    "        hist_batch (torch.Tensor): A tensor of shape [batch_size, 2, 50] representing a batch of histograms.\n",
    "        shift_tensors (torch.Tensor): A tensor of shape [batch_size, 1] representing the shift proportions for each histogram.\n",
    "        x_range (tuple): The range of the x-axis as (min, max).\n",
    "        y_range (tuple): The range of the y-axis as (min, max).\n",
    "    \n",
    "        Returns:\n",
    "        torch.Tensor: The translated histograms with out-of-bounds values ignored and zeros filled.\n",
    "        \"\"\"\n",
    "        num_bins = hist_batch.shape[-1]\n",
    "        #bin_width = (lim_min - lim_max) / num_bins\n",
    "\n",
    "        shift_tensors = shift_tensors * 2 - 1\n",
    "    \n",
    "        # Calculate the number of bins to shift for each histogram in the batch\n",
    "        translation_bins = (shift_tensors * num_bins).long() # Shape: [batch_size]\n",
    "        \n",
    "        translated_hist_batch = torch.zeros_like(hist_batch)\n",
    "        bin_indices = torch.arange(num_bins, device=hist_batch.device).unsqueeze(0)  # Shape: [1, num_bins]\n",
    "        #print(\"translation_bins\", translation_bins.shape)\n",
    "        #print(\"bin_indices\", bin_indices.shape)\n",
    "        #print(\"translation_bins.unsqueeze_1\", translation_bins.unsqueeze(1).shape)\n",
    "        # Calculate the valid indices after translation for each histogram\n",
    "        valid_indices = bin_indices - translation_bins.unsqueeze(-1)  # Shape: [batch_size, num_bins]\n",
    "        \n",
    "        \n",
    "        valid_mask = (valid_indices >= 0) & (valid_indices < num_bins)  # Mask for valid positions\n",
    "        valid_indices = torch.where(valid_mask, valid_indices, 0)\n",
    "        #print(\"valid_indices\", valid_indices, valid_indices.shape)\n",
    "        #print(valid_indices, valid_mask)\n",
    "        #print(translated_hist_batch.shape, valid_mask.shape, valid_indices.shape, valid_indices[valid_mask])\n",
    "        # Translate the x-axis values (first row of histograms)\n",
    "        #print(\"hist_batch shape\", hist_batch.shape)\n",
    "        #translated_hist_batch = hist_batch[:,valid_indices] # hist_batch[valid_indices[valid_mask]]\n",
    "        #print(hist_batch.shape, valid_indices.shape)\n",
    "        #print(\"valid_indices\", valid_indices)\n",
    "        #print(\"hist_batch.shape\", hist_batch.shape)\n",
    "        translated_hist_batch = torch.gather(hist_batch, -1, valid_indices)\n",
    "        #print(\"uh oh no gather\")\n",
    "        translated_hist_batch = torch.where(valid_mask, translated_hist_batch, torch.zeros_like(translated_hist_batch))\n",
    "        #print(\"kay we got through\")\n",
    "        # Copy the y-axis values (second row) without modification\n",
    "        #translated_hist_batch[:, 1, :] = hist_batch[:, 1, :]\n",
    "    \n",
    "        return translated_hist_batch\n",
    "model = Model()\n",
    "\n",
    "#batch_size = 2\n",
    "#hist_batch = torch.rand(batch_size, 5)  # Create a batch of 4 random 2x50 histograms\n",
    "#shift_tensors = torch.rand(batch_size)  # Shifts by 10%, 50%, 75%, and 30%\n",
    "#print(\"in\", hist_batch)\n",
    "#translated_hist_batch = Model.batch_translate_histograms(hist_batch, shift_tensors)\n",
    "#print(\"out\", translated_hist_batch)\n",
    "#indices = torch.tensor([[-4, -3, -2, -1,  0], [-4, -3, -2, -1,  0]])\n",
    "#print(indices.shape)\n",
    "#print(hist_batch.T[indices].shape)\n",
    "\n",
    "#model(torch.randn(4, 5, 36, device=model.device))\n",
    "#a = torch.arange(3).repeat(2,1)\n",
    "#print(a)\n",
    "#print(\"\\nTranslated Histogram Batch:\")\n",
    "\n",
    "#print(translated_hist_batch)\n",
    "#indices = torch.tensor([[1,0,1],[1,1,0]])\n",
    "#print(\"indices\", indices, indices.shape)\n",
    "\n",
    "#print(a[indices], a[indices].shape)\n",
    "\n",
    "#torch.index_select(input, dim, indices,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764b435d-3734-46db-bbae-f6d3710e1938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_good_offset_problem(model, iterations=10000, offset_trials=100, max_offset=0.2, beamline_trials=1000):    \n",
    "    for i in tqdm.tqdm(range(iterations)):\n",
    "        offsets = (torch.rand(1, offset_trials, 34, device=model.device) * max_offset * 2) - max_offset\n",
    "        uncompensated_parameters = torch.rand(beamline_trials, 1, offsets.shape[-1], device=model.device)\n",
    "        tensor_sum = offsets + uncompensated_parameters\n",
    "        tensor_sum = torch.clamp(tensor_sum, 0, 1)\n",
    "        uncompensated_parameters = tensor_sum - offsets\n",
    "        with torch.no_grad():\n",
    "            compensated_rays = model(tensor_sum)\n",
    "            #condition = compensated_rays.sum(dim=-1) > 1.3\n",
    "            condition = (compensated_rays.sum(dim=-1)>0.5).sum(dim=0)>15\n",
    "            if condition.any():\n",
    "                result = (compensated_rays.sum(dim=-1)>0.5).sum(dim=0)[condition]\n",
    "                print(str(len(result))+\" results.\")\n",
    "                condition_args = torch.arange(len(condition), device=model.device)[condition][:1]\n",
    "                mask = compensated_rays[:, condition_args[0]].sum(dim=-1)>0.5\n",
    "                to_plot_tensor = tensor_sum[:, condition_args][mask]\n",
    "                uncompensated_parameters_selected = uncompensated_parameters[:, condition_args][mask]\n",
    "                offsets_selected = offsets[:, condition_args]\n",
    "                break\n",
    "    compensated_parameters_selected = uncompensated_parameters_selected+offsets_selected\n",
    "    return offsets_selected, uncompensated_parameters_selected, compensated_parameters_selected\n",
    "offsets_selected, uncompensated_parameters_selected, compensated_parameters_selected = find_good_offset_problem(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea8d830-7098-455f-a129-8e6f16bf0baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_brute(model, observed_rays, uncompensated_parameters, offset_trials=100000, max_offset=0.2, num_iterations=10000):\n",
    "    observed_rays = observed_rays.to(model.device)\n",
    "    loss_min = float('inf')\n",
    "    pbar = tqdm.trange(num_iterations)\n",
    "    loss_min_params = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in pbar:\n",
    "            offsets = (torch.rand((1, offset_trials, uncompensated_parameters.shape[-1]), device=model.device) * max_offset * 2) - max_offset\n",
    "            tensor_sum = offsets + uncompensated_parameters\n",
    "            \n",
    "            compensated_rays = model(tensor_sum)\n",
    "            loss_orig = ((compensated_rays - observed_rays) ** 2).mean(0).mean(-1)\n",
    "            loss = loss_orig.min()\n",
    "            if loss < loss_min:\n",
    "                loss_min = loss\n",
    "                loss_min_params = tensor_sum[:, loss_orig.argmin(), :]\n",
    "                pbar.set_postfix({\"loss\": loss_min.item()})\n",
    "    return loss_min_params\n",
    "\n",
    "def optimize_smart_walker(model, observed_rays, uncompensated_parameters, num_candidates=100000, max_offset=0.2, step_width=0.02, num_iterations=1000):\n",
    "    loss_min = float('inf')\n",
    "    offsets = (torch.rand(1, num_candidates, uncompensated_parameters.shape[-1], device=model.device) * max_offset * 2) - max_offset\n",
    "    \n",
    "    pbar = tqdm.trange(num_iterations)\n",
    "    with torch.no_grad():\n",
    "        for i in pbar:\n",
    "            offsets = offsets + (torch.randn(offsets.shape[0], num_candidates, offsets.shape[-1], device=model.device) * step_width)\n",
    "            offsets = torch.clamp(offsets, -max_offset, max_offset)\n",
    "            tensor_sum = offsets + uncompensated_parameters\n",
    "            \n",
    "            compensated_rays = model(tensor_sum)\n",
    "            compensated_rays = compensated_rays.flatten(start_dim=2)\n",
    "            loss_orig = ((compensated_rays - observed_rays) ** 2).mean(0).mean(-1)\n",
    "        \n",
    "            loss = loss_orig.min()\n",
    "            offsets = offsets[:, loss_orig.argmin(), :].unsqueeze(dim=1)\n",
    "            if loss < loss_min:\n",
    "                loss_min = loss.item()\n",
    "                loss_min_params = tensor_sum[:, loss_orig.argmin(), :]\n",
    "                pbar.set_postfix({\"loss\": loss.item()})\n",
    "    return loss_min_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b7afa-1439-44ba-8200-ce731d26340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    observed_rays = model(compensated_parameters_selected)\n",
    "\n",
    "loss_min_params = optimize_smart_walker(model, observed_rays, uncompensated_parameters_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4765ab94-0f73-4c31-b52d-b11ae0bfe002",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_observed_rays = observed_rays.squeeze()\n",
    "plot_min_param_rays = model(loss_min_params)\n",
    "fig, ax = plt.subplots(1, plot_observed_rays.shape[0], sharex=True, sharey=True, figsize=(32, 9))\n",
    "with torch.no_grad():\n",
    "    for i in range(plot_observed_rays.shape[0]):\n",
    "        ax[i].plot(model(loss_min_params)[i].cpu())\n",
    "        ax[i].plot(observed_rays.squeeze()[i].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca2dfaf-7a6b-4d4a-a66c-1b0c9f4e2330",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_tensors(loss_min_params[[1,2,3,4,7]], uncompensated_parameters_selected[[1,2,3,4,7]], compensated_parameters=compensated_parameters_selected[[1,2,3,4,7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26899f5-568d-4447-af06-fc8786606588",
   "metadata": {},
   "source": [
    "# Import real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2faae3b-c24d-42dc-89fd-7043dd4eaf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_real_hist_data(path = 'datasets/metrix_real_data/2021_march_complete', import_set = ['M03', 'M10', 'M18', 'M22', 'M23', 'M24', 'M25', 'M27', 'M28', 'M29', 'M30', 'M32', 'M33', 'M36',\n",
    "                             'M37', 'M40', 'M41', 'M42', 'M43', 'M44'], check_value_lims=False):\n",
    "    imported_data = import_data(\n",
    "                path,\n",
    "                import_set,\n",
    "                [0.],\n",
    "                params(),\n",
    "                check_value_lims=check_value_lims,\n",
    "            )\n",
    "    xy_hist = XYHistogram(50, (-10., 10.), (-3., 3.))\n",
    "    \n",
    "    real_data_list = []\n",
    "    for i in range(len(imported_data)):\n",
    "        real_data_list.append(xy_hist(imported_data[i]['ray_output']['ImagePlane']))\n",
    "    \n",
    "    real_data_point_cloud_list = []\n",
    "    for i in range(len(imported_data)):\n",
    "        real_data_point_cloud_list.append(imported_data[i])\n",
    "    \n",
    "    real_data_tensor = torch.stack([real_data_list[i][0.0]['histogram'] for i in range(len(real_data_list))])\n",
    "    real_data_tensor_normalized = surrogate_engine.model.standardizer(real_data_tensor)\n",
    "    \n",
    "    uncompensated_parameters_list = []\n",
    "    for i in range(len(imported_data)):\n",
    "        uncompensated_entry = torch.tensor([value.get_value() for value in Plot.normalize_parameters(imported_data[i]['param_container_dict'], params()).values()])\n",
    "        uncompensated_parameters_list.append(uncompensated_entry)\n",
    "    uncompensated_parameters = torch.stack(uncompensated_parameters_list)\n",
    "    \n",
    "    observed_rays = real_data_tensor_normalized.flatten(start_dim=1).unsqueeze(1).float().to(model.device)\n",
    "    uncompensated_parameters = uncompensated_parameters.unsqueeze(1).float().to(model.device)\n",
    "    observed_rays_point_cloud = ray_output_to_tensor(real_data_point_cloud_list, 'ImagePlane')\n",
    "    return observed_rays, uncompensated_parameters, observed_rays_point_cloud\n",
    "observed_rays_real, uncompensated_parameters_real, observed_rays_point_cloud = import_real_hist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58b100-897d-45a2-aa64-73361f5b6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_min_params = optimize_smart_walker(model, observed_rays_real, uncompensated_parameters_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec1683-db55-411e-94f5-c232488db214",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device('cpu')\n",
    "pc = [tensor_to_param_container(loss_min_params[i]) for i in range(loss_min_params.shape[0])]\n",
    "Plot.plot_engines_comparison(engine, surrogate_engine, pc[:8], MultiLayer([0.]), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2c876-88bd-41e1-a73c-088c9b82b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_list_to_param_container_list = lambda input_param_tensor: [tensor_to_param_container(input_param_tensor[i].squeeze()) for i in range(input_param_tensor.shape[0])]\n",
    "\n",
    "\n",
    "def simulate_param_tensor(input_param_tensor):\n",
    "    #print(\"simulating\", input_param_tensor.shape)\n",
    "    pc = tensor_list_to_param_container_list(input_param_tensor[...,:34])\n",
    "    param_container_list = []\n",
    "    for i in input_param_tensor:\n",
    "        i = i.squeeze()\n",
    "        param_container_list.append(\n",
    "            RayParameterContainer([\n",
    "            ('ImagePlane.translationXerror', NumericalOutputParameter(value=(i[-2].item()-0.5)*20)),\n",
    "            ('ImagePlane.translationYerror', NumericalOutputParameter(value=(i[-1].item()-0.5)*4)),\n",
    "            ]))\n",
    "    #print(\"pcl\",param_container_list)\n",
    "\n",
    "    #ray_parameter_container_list = []\n",
    "    #for key in (\"translationXerror\", \"translationYerror\"):\n",
    "    #    ray_parameter_container_list.append(key\n",
    "\n",
    "    #RayParameterContainer(['U41_318eV.numberRays', OutputNumericalParameter(value=33333)])\n",
    "        \n",
    "    exported_plain_transforms = RayOptimizer.translate_exported_plain_transforms(\n",
    "        exported_plane=\"ImagePlane\",\n",
    "        param_container_list=param_container_list,\n",
    "        transform = MultiLayer([0.]),\n",
    "    )\n",
    "    #print(\"ept\",exported_plain_transforms)\n",
    "    engine_output = engine.run(pc, exported_plain_transforms)\n",
    "    return ray_output_to_tensor(engine_output, 'ImagePlane')\n",
    "\n",
    "def plot_param_tensors(best_parameters, uncompensated_parameters, observed_rays_point_cloud=None, compensated_parameters=None):\n",
    "    assert observed_rays_point_cloud is not None or compensated_parameters is not None # you should provide one of two\n",
    "    if compensated_parameters is not None:\n",
    "        observed_rays = simulate_param_tensor(compensated_parameters)\n",
    "    else:\n",
    "        observed_rays = observed_rays_point_cloud\n",
    "    best_rays = simulate_param_tensor(best_parameters)\n",
    "    uncompensated_rays = simulate_param_tensor(uncompensated_parameters)\n",
    "    \n",
    "    #compensation_plot = Plot.fixed_position_plot(\n",
    "    compensation_plot = Plot.compensation_plot(\n",
    "        best_rays,\n",
    "        observed_rays,\n",
    "        uncompensated_rays,\n",
    "        #xlim=(-10.,10.),\n",
    "        #ylim=(-2.,2.),\n",
    "        epoch=42,\n",
    "        training_samples_count=len(observed_rays),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2f2b8-bac3-49ac-98eb-3d8fc157054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_tensors(loss_min_params[:], uncompensated_parameters_selected[:], compensated_parameters=compensated_parameters_selected[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccf28d6-559e-4c95-bc95-360d71a6eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_params = torch.vstack(10*[loss_min_params[1]])\n",
    "a = repeated_params.clone()\n",
    "b = repeated_params.clone()\n",
    "c = repeated_params.clone()\n",
    "for i, ten in enumerate(a):\n",
    "    ten[-1]=0.5+0.1*i\n",
    "    ten[-2]=0.5\n",
    "for i, ten in enumerate(b):\n",
    "    ten[-2]=0.5+0.1*i\n",
    "    ten[-1]=0.5\n",
    "for i, ten in enumerate(c):\n",
    "    ten[-1]=0.5\n",
    "    ten[-2]=0.5#+0.005*i\n",
    "plot_param_tensors(a[:3], b[:3], compensated_parameters=c[:3])\n",
    "#print(repeated_params)\n",
    "#plot_param_tensors(loss_min_params[:], uncompensated_parameters_selected[:], compensated_parameters=compensated_parameters_selected[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a87724d-4ca2-433d-9957-e4f8ae902631",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_min_params.shape, uncompensated_parameters_selected.shape, compensated_parameters_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0e49fe-5a57-4edf-a8f4-fab2f552d124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ef0d19-7c06-4a60-acc3-b5114c15cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_comparison_plot = Plot.plot_param_comparison(\n",
    "    predicted_params=tensor_list_to_param_container_list(loss_min_params.squeeze().unsqueeze(0)),\n",
    "    epoch=42,\n",
    "    training_samples_count=len(observed_rays),\n",
    "    search_space=params(),\n",
    "    real_params=tensor_list_to_param_container_list(compensated_parameters_selected)[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217c54c-b558-41f1-9e7a-66b78f1bdc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_comparison_plot = Plot.plot_param_comparison(\n",
    "    predicted_params=tensor_to_param_container(offsets_selected.squeeze()),\n",
    "    epoch=42,\n",
    "    training_samples_count=len(observed_rays),\n",
    "    search_space=RayOptimization.limited_search_space(params(), RandomGenerator(42), max_deviation=max_offset),\n",
    "    real_params=tensor_list_to_param_container_list(loss_min_params[0] - compensated_parameters_selected.squeeze())[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c91816-b241-4f86-ba22-b4f610b91e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import transforms\n",
    "import numpy as np\n",
    "from matplotlib.layout_engine import ConstrainedLayoutEngine, TightLayoutEngine\n",
    "from matplotlib.ticker import NullLocator\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "rs = np.random.RandomState(11)\n",
    "x = rs.gamma(4, size=1000)\n",
    "y = -.5 * x + rs.normal(size=1000)\n",
    "x = x / 4  -1\n",
    "y = y/4 +1\n",
    "\n",
    "\n",
    "def scatter_hist(x, y, ax, ax_histx, ax_histy):\n",
    "    xlim_min, xlim_max, ylim_min, ylim_max = -2, 2, -2, 2\n",
    "    # no labels\n",
    "    ax_histx.tick_params(axis=\"x\", labelbottom=False)\n",
    "    ax_histy.tick_params(axis=\"y\", labelleft=False)\n",
    "\n",
    "    # the scatter plot:\n",
    "    color = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][1]\n",
    "    ax.scatter(\n",
    "    x,\n",
    "    y,\n",
    "    s=2.0,\n",
    "    alpha=0.5,\n",
    "    linewidths=0.4,\n",
    "    color=color\n",
    "    )\n",
    "    ax.set_xlim(\n",
    "    Plot.scale_interval(\n",
    "        xlim_min, xlim_max, 1.2\n",
    "    )\n",
    ")\n",
    "    ax.set_ylim(\n",
    "        Plot.scale_interval(\n",
    "            ylim_min, ylim_max, 1.2\n",
    "        )\n",
    "    )\n",
    "    ax.tick_params(axis=\"both\", length=0.0)\n",
    "    ax.grid(linestyle=\"dashed\", alpha=0.5)\n",
    "    ax.xaxis.set_major_locator(NullLocator())\n",
    "    ax.yaxis.set_major_locator(NullLocator())\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter(\"%.1f\"))\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.1f\"))\n",
    "    \n",
    "    ax.set_xticks((xlim_min, xlim_max))\n",
    "    ax.set_yticks((ylim_min, ylim_max))\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "    # now determine nice limits by hand:\n",
    "    binwidth = 0.25\n",
    "    xymax = max(np.max(np.abs(x)), np.max(np.abs(y)))\n",
    "    lim = (int(xymax/binwidth) + 1) * binwidth\n",
    "\n",
    "    bins = np.arange(-lim, lim + binwidth, binwidth)\n",
    "    #ax_histx.hist(x, bins=bins, color=color)\n",
    "    x_simulation_hist, _ = torch.histogram(torch.from_numpy(x),bins=50, range=[-2, 2])\n",
    "    ax_histx.plot(torch.linspace(-2, 2, 50), x_simulation_hist, color=color)\n",
    "    ax_histx.set_yticklabels([])\n",
    "    #ax_histy.hist(y, bins=bins, orientation='horizontal', color=color)\n",
    "    y_simulation_hist, _ = torch.histogram(torch.from_numpy(y),bins=50, range=[-2, 2])\n",
    "    ax_histy.plot(y_simulation_hist, torch.linspace(-2, 2, 50), color=color)\n",
    "    ax_histy.set_xticklabels([])\n",
    "\n",
    "\n",
    "# Create a Figure, which doesn't have to be square.\n",
    "fig = plt.figure(layout='constrained')\n",
    "# Create the main Axes, leaving 25% of the figure space at the top and on the\n",
    "# right to position marginals.\n",
    "ax = fig.add_gridspec(top=0.75, right=0.75).subplots()\n",
    "# The main Axes' aspect can be fixed.\n",
    "ax.set(aspect=1)\n",
    "# Create marginal Axes, which have 25% of the size of the main Axes.  Note that\n",
    "# the inset Axes are positioned *outside* (on the right and the top) of the\n",
    "# main Axes, by specifying axes coordinates greater than 1.  Axes coordinates\n",
    "# less than 0 would likewise specify positions on the left and the bottom of\n",
    "# the main Axes.\n",
    "ax_histx = ax.inset_axes([0, 1.05, 1, 0.25], sharex=ax)\n",
    "ax_histy = ax.inset_axes([1.05, 0, 0.25, 1], sharey=ax)\n",
    "# Draw the scatter plot and marginals.\n",
    "scatter_hist(x, y, ax, ax_histx, ax_histy)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a99514-298b-46ac-930e-172fd0d86950",
   "metadata": {},
   "source": [
    "# Evotorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224f1d6-2833-418a-848c-3f26d28e4bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evotorch import Problem\n",
    "from evotorch.algorithms import SNES\n",
    "from evotorch.logging import StdOutLogger\n",
    "\n",
    "def norm(x: torch.Tensor) -> torch.Tensor:\n",
    "  return torch.linalg.norm(x, dim=-1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    observed_rays = model(compensated_parameters_selected)\n",
    "uncompensated_parameters = uncompensated_parameters_selected\n",
    "def loss(x: torch.Tensor) -> torch.Tensor:\n",
    "    with torch.no_grad():\n",
    "        tensor_sum = x + uncompensated_parameters\n",
    "        compensated_rays = model(tensor_sum, clone_output=True)\n",
    "        compensated_rays = compensated_rays.flatten(start_dim=2)\n",
    "        loss_orig = ((compensated_rays - observed_rays) ** 2).mean(0).mean(-1)\n",
    "    return loss_orig\n",
    "\n",
    "problem = Problem(\n",
    "  \"min\",\n",
    "  loss,\n",
    "  initial_bounds=(0., 1.),\n",
    "  solution_length=36,\n",
    "  vectorized=True,\n",
    "  device=\"cuda\",  # Enable for GPU support\n",
    ")\n",
    "\n",
    "searcher = SNES(problem, popsize=1000, stdev_init=0.2)\n",
    "_ = StdOutLogger(searcher, interval=100)\n",
    "\n",
    "searcher.run(num_generations=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bef591-1594-40af-bd3c-e862a9603f56",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a98980-c87c-4bd4-a775-e92dc0062c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "x = torch.rand((batch_size, 36), requires_grad=True, device=model.device)\n",
    "optimizer = torch.optim.SGD([x], lr=0.01)  # Adjust the learning rate as needed\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "num_epochs = 1000  # Number of iterations\n",
    "uncompensated_parameters = uncompensated_parameters_selected\n",
    "#with torch.no_grad():\n",
    "observed_rays = model(compensated_parameters_selected)\n",
    "\n",
    "def function_to_minimize(x):\n",
    "    tensor_sum = x + uncompensated_parameters\n",
    "    compensated_rays = model(tensor_sum)\n",
    "    compensated_rays = compensated_rays.flatten(start_dim=2)\n",
    "    loss_orig = ((compensated_rays - observed_rays) ** 2).mean(0).mean(-1)\n",
    "    return loss_orig\n",
    "\n",
    "pbar = tqdm.trange(num_epochs)\n",
    "for epoch in pbar:\n",
    "    optimizer.zero_grad()  # Clear the gradients from the previous step\n",
    "    \n",
    "    output = function_to_minimize(x.detach())  # Compute the function's output\n",
    "    loss = output.mean()  # Compute the mean loss for this batch\n",
    "    \n",
    "    loss.backward(retain_graph=True)  # Backpropagate to compute the gradients\n",
    "    optimizer.step()  # Update the parameters with SGD\n",
    "    \n",
    "    # Optionally print the loss to monitor progress\n",
    "    if epoch % 100 == 0:\n",
    "        pbar.set_postfix({\"loss\": loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c76e72-5578-401a-94da-a26d460c609c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
